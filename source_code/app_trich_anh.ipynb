{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1235b4d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc1c0063fe964ebc968f05cd1751a73d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\envs\\coco_kg\\lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\admin\\.cache\\huggingface\\hub\\models--Salesforce--blip-image-captioning-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "\n",
    "# Tải mô hình\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e4c5c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ảnh\n",
    "img = Image.open(\"E:/Download/val2017/000000000785.jpg\").convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e967930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caption sinh ra: a woman in a red jacket skiing down a hill\n"
     ]
    }
   ],
   "source": [
    "# Tiền xử lý và caption\n",
    "inputs = processor(img, return_tensors=\"pt\")\n",
    "out = model.generate(**inputs)\n",
    "caption = processor.decode(out[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Caption sinh ra:\", caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8743d299",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import torch\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.data import MetadataCatalog\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import Counter\n",
    "import spacy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddc8422d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load mô hình Detectron2 để detect object\n",
    "def load_detectron2():\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(model_zoo.get_config_file(\n",
    "        \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
    "    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\n",
    "        \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "    cfg.MODEL.DEVICE = \"cpu\"  \n",
    "    predictor = DefaultPredictor(cfg)\n",
    "    class_names = MetadataCatalog.get(cfg.DATASETS.TRAIN[0]).thing_classes\n",
    "    return predictor, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "925a8111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load mô hình BLIP sinh caption\n",
    "@st.cache_resource\n",
    "def load_blip():\n",
    "    processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "    model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "    return processor, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "161e8938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Load dữ liệu R-GCN đã huấn luyện\n",
    "@st.cache_resource\n",
    "def load_support_files():\n",
    "    with open(\"saved_model_R_GCN/entity_encoder.pkl\", \"rb\") as f:\n",
    "        entity_encoder = pickle.load(f)\n",
    "    with open(\"saved_model_R_GCN/entity_idx_to_images.pkl\", \"rb\") as f:\n",
    "        entity_idx_to_images = pickle.load(f)\n",
    "    with open(\"saved_model_R_GCN/synonym_map.pkl\", \"rb\") as f:\n",
    "        synonym_map = pickle.load(f)\n",
    "    return entity_encoder, entity_idx_to_images, synonym_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22b3fcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. spaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff1c32ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Function \n",
    "def extract_triplets(caption, labels):\n",
    "    triplets = []\n",
    "    subject = \"person\" if \"person\" in labels else (labels[0] if labels else None)\n",
    "    predicate = caption.split()[1] if len(caption.split()) > 1 else \"interacts\"\n",
    "\n",
    "    if subject:\n",
    "        for obj in labels:\n",
    "            if obj != subject:\n",
    "                triplets.append((subject, predicate, obj))\n",
    "    return triplets\n",
    "\n",
    "# Hàm cải tiến: Trích triplet bằng NLP nếu thiếu object từ detectron2\n",
    "def extract_multiple_triplets_from_caption(caption):\n",
    "    doc = nlp(caption)\n",
    "    subjects, predicate, objects = [], None, []\n",
    "    noun_candidates = [t for t in doc if t.pos_ == \"NOUN\"]\n",
    "\n",
    "    if noun_candidates:\n",
    "        first_noun = noun_candidates[0]\n",
    "        subjects.append(first_noun.text.lower())\n",
    "        for token in noun_candidates[1:]:\n",
    "            if token.dep_ == \"conj\" or token.head == first_noun:\n",
    "                subjects.append(token.text.lower())\n",
    "\n",
    "    for token in doc:\n",
    "        if token.dep_ == \"ROOT\" and token.pos_ == \"VERB\":\n",
    "            predicate = token.text.lower()\n",
    "            break\n",
    "    if predicate is None:\n",
    "        for token in doc:\n",
    "            if token.dep_ == \"acl\" and token.pos_ == \"VERB\":\n",
    "                predicate = token.text.lower()\n",
    "                break\n",
    "\n",
    "    for token in doc:\n",
    "        if token.dep_ in (\"dobj\", \"pobj\", \"attr\") and token.pos_ == \"NOUN\":\n",
    "            objects.append(token.text.lower())\n",
    "        elif token.dep_ == \"conj\" and token.head.dep_ in (\"dobj\", \"pobj\", \"attr\"):\n",
    "            objects.append(token.text.lower())\n",
    "\n",
    "    if predicate is None and not objects:\n",
    "        for token in doc:\n",
    "            if token.dep_ == \"prep\":\n",
    "                pobj = next((t for t in token.children if t.dep_ == \"pobj\" and t.pos_ == \"NOUN\"), None)\n",
    "                if pobj:\n",
    "                    objects.append(pobj.text.lower())\n",
    "\n",
    "    triplets = []\n",
    "    if subjects and objects:\n",
    "        for subj in subjects:\n",
    "            for obj in objects:\n",
    "                triplets.append((subj, predicate, obj))\n",
    "    elif subjects:\n",
    "        triplets = [(subj, predicate, None) for subj in subjects]\n",
    "    return triplets\n",
    "\n",
    "def normalize(word, entity_encoder, synonym_map):\n",
    "    if not word:\n",
    "        return None\n",
    "    word_lower = word.lower()\n",
    "    word_norm = synonym_map.get(word_lower, word_lower)\n",
    "    if word_norm in entity_encoder.classes_:\n",
    "        return word_norm\n",
    "    if word_norm.endswith(\"ing\"):\n",
    "        root = word_norm[:-3]\n",
    "        if root in entity_encoder.classes_:\n",
    "            return root\n",
    "    lemma = nlp(word_norm)[0].lemma_\n",
    "    if lemma in entity_encoder.classes_:\n",
    "        return lemma\n",
    "    return word_norm\n",
    "\n",
    "def get_id(word, entity_encoder, label, raw_word):\n",
    "    if word:\n",
    "        try:\n",
    "            idx = entity_encoder.transform([word])[0]\n",
    "            return idx\n",
    "        except:\n",
    "            pass\n",
    "    return None\n",
    "\n",
    "def find_images(triplets, entity_encoder, entity_idx_to_images, synonym_map):\n",
    "    image_counter = Counter()\n",
    "    for subj_raw, pred_raw, obj_raw in triplets:\n",
    "        subj = normalize(subj_raw, entity_encoder, synonym_map)\n",
    "        pred = normalize(pred_raw, entity_encoder, synonym_map)\n",
    "        obj = normalize(obj_raw, entity_encoder, synonym_map)\n",
    "\n",
    "        subj_id = get_id(subj, entity_encoder, \"subject\", subj_raw)\n",
    "        pred_id = get_id(pred, entity_encoder, \"predicate\", pred_raw)\n",
    "        obj_id = get_id(obj, entity_encoder, \"object\", obj_raw)\n",
    "\n",
    "        imgs = set()\n",
    "        if subj_id is not None and obj_id is not None:\n",
    "            subj_imgs = set(entity_idx_to_images.get(subj_id, []))\n",
    "            obj_imgs = set(entity_idx_to_images.get(obj_id, []))\n",
    "            core_imgs = subj_imgs & obj_imgs\n",
    "            if pred_id is not None:\n",
    "                pred_imgs = set(entity_idx_to_images.get(pred_id, []))\n",
    "                imgs = core_imgs & pred_imgs or core_imgs\n",
    "            else:\n",
    "                imgs = core_imgs\n",
    "        elif subj_id is not None and pred_id is not None:\n",
    "            imgs = set(entity_idx_to_images.get(subj_id, [])) & set(entity_idx_to_images.get(pred_id, []))\n",
    "        elif obj_id is not None:\n",
    "            imgs = set(entity_idx_to_images.get(obj_id, []))\n",
    "        image_counter.update(imgs)\n",
    "\n",
    "    sorted_image_ids = [img_id for img_id, _ in image_counter.most_common()]\n",
    "    return [f\"{int(img_id):012}.jpg\" for img_id in sorted_image_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2efd0098",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 06:27:27.622 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-07 06:27:27.625 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-07 06:27:27.627 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-07 06:27:27.627 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-07 06:27:27.630 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-07 06:27:27.630 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-07 06:27:27.630 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-07 06:27:27.630 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "# 5. Giao diện Streamlit\n",
    "st.set_page_config(\n",
    "    page_title=\"Tìm ảnh từ Ảnh\",\n",
    "    layout=\"wide\",\n",
    "    initial_sidebar_state=\"auto\"\n",
    ")\n",
    "\n",
    "st.title(\"Truy vấn ảnh từ hình ảnh đầu vào\")\n",
    "\n",
    "uploaded_file = st.file_uploader(\"Chọn một ảnh để truy vấn\", type=[\"jpg\", \"png\"])\n",
    "\n",
    "if uploaded_file:\n",
    "    image = Image.open(uploaded_file).convert(\"RGB\")\n",
    "    st.image(image, caption=\"Ảnh đã chọn\", use_container_width=True)\n",
    "\n",
    "    with st.spinner(\"Đang xử lý...\"):\n",
    "        # Load models\n",
    "        processor, blip_model = load_blip()\n",
    "        predictor, class_names = load_detectron2()\n",
    "        entity_encoder, entity_idx_to_images, synonym_map = load_support_files()\n",
    "\n",
    "        # BLIP caption\n",
    "        inputs = processor(images=image, return_tensors=\"pt\")\n",
    "        out = blip_model.generate(**inputs)\n",
    "        caption = processor.decode(out[0], skip_special_tokens=True)\n",
    "        st.subheader(\"Caption:\")\n",
    "        st.write(caption)\n",
    "\n",
    "        # Detect objects\n",
    "        outputs = predictor(np.array(image))\n",
    "        label_ids = outputs[\"instances\"].pred_classes.tolist()\n",
    "        labels = list(set([class_names[i] for i in label_ids]))\n",
    "        st.subheader(\"Các đối tượng phát hiện:\")\n",
    "        st.write(\", \".join(labels))\n",
    "\n",
    "        # Extract triplets: dùng Detectron2 nếu có labels, nếu không thì dùng NLP\n",
    "        if labels:\n",
    "            triplets = extract_triplets(caption, labels)\n",
    "        else:\n",
    "            triplets = extract_multiple_triplets_from_caption(caption)\n",
    "\n",
    "        # Hiển thị triplets\n",
    "        st.subheader(\"Triplets trích xuất:\")\n",
    "        if triplets:\n",
    "            for t in triplets:\n",
    "                st.write(f\"- {t}\")\n",
    "        else:\n",
    "            st.warning(\"Không trích xuất được triplet nào từ caption.\")\n",
    "\n",
    "        # Find images\n",
    "        result_images = find_images(triplets, entity_encoder, entity_idx_to_images, synonym_map)\n",
    "        if result_images:\n",
    "            st.success(f\"Tìm thấy {len(result_images)} ảnh phù hợp.\")\n",
    "            for i in range(0, len(result_images), 3):\n",
    "                cols = st.columns(3)\n",
    "                for j in range(3):\n",
    "                    if i + j < len(result_images):\n",
    "                        img_path = os.path.join(\"E:/Download/val2017\", result_images[i + j])\n",
    "                        if os.path.exists(img_path):\n",
    "                            with cols[j]:\n",
    "                                st.image(Image.open(img_path), caption=result_images[i + j], use_container_width=True)\n",
    "        else:\n",
    "            st.warning(\"Không tìm thấy ảnh nào phù hợp.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e22021",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
