{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ecd087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import dgl\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "\n",
    "# 1. Đọc dữ liệu và tạo đồ thị\n",
    "df = pd.read_csv('triplets_from_captions_val2017.csv').dropna().astype(str)\n",
    "triplets = list(zip(df['subject'], df['predicate'], df['object'], df['image_id']))\n",
    "\n",
    "G = nx.DiGraph()\n",
    "for s, p, o, img_id in triplets:\n",
    "    mid = f\"{s}_{p}_{o}\"\n",
    "    G.add_edge(s, mid, relation=p)\n",
    "    G.add_edge(mid, o, relation=p)\n",
    "    G.nodes[mid]['image_id'] = img_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81873fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Mã hóa node và quan hệ\n",
    "all_nodes = list(G.nodes)\n",
    "le = LabelEncoder()\n",
    "node_ids = le.fit_transform(all_nodes)\n",
    "node_id_map = dict(zip(all_nodes, node_ids))\n",
    "\n",
    "edges_src = [node_id_map[u] for u, v in G.edges()]\n",
    "edges_dst = [node_id_map[v] for u, v in G.edges()]\n",
    "edge_types = [G[u][v]['relation'] for u, v in G.edges()]\n",
    "rel_encoder = LabelEncoder()\n",
    "edge_type_ids = rel_encoder.fit_transform(edge_types)\n",
    "edge_type_tensor = torch.tensor(edge_type_ids, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2a02fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Tạo đồ thị DGL\n",
    "g = dgl.graph((edges_src, edges_dst), num_nodes=len(all_nodes))\n",
    "g = dgl.add_self_loop(g)\n",
    "num_self_loops = g.number_of_edges() - len(edge_type_tensor)\n",
    "self_loop_type = torch.full((num_self_loops,), fill_value=len(set(edge_type_ids)), dtype=torch.int64)\n",
    "edge_type_tensor = torch.cat([edge_type_tensor, self_loop_type], dim=0)\n",
    "\n",
    "features = torch.eye(len(all_nodes))\n",
    "num_rels = len(set(edge_type_tensor.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bcdcb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Định nghĩa mô hình R-GCN\n",
    "class RGCN(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, out_feats, num_rels):\n",
    "        super(RGCN, self).__init__()\n",
    "        self.conv1 = dgl.nn.RelGraphConv(in_feats, h_feats, num_rels)\n",
    "        self.conv2 = dgl.nn.RelGraphConv(h_feats, out_feats, num_rels)\n",
    "\n",
    "    def forward(self, g, x, etype):\n",
    "        h = self.conv1(g, x, etype)\n",
    "        h = torch.relu(h)\n",
    "        h = self.conv2(g, h, etype)\n",
    "        return h\n",
    "\n",
    "model = RGCN(features.shape[1], 64, 128, num_rels)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50dc92e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Khởi tạo và chạy mô hình R-GCN (không huấn luyện)\n",
    "model = RGCN(features.shape[1], 64, 128, num_rels)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    node_embeddings = model(g, features, edge_type_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdd1bc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Trung bình embedding ảnh\n",
    "embeddings = node_embeddings.numpy()\n",
    "image_embeddings = defaultdict(list)\n",
    "\n",
    "for node, idx in node_id_map.items():\n",
    "    if 'image_id' in G.nodes[node]:\n",
    "        img_id = G.nodes[node]['image_id']\n",
    "        image_embeddings[img_id].append(embeddings[idx])\n",
    "\n",
    "for img in image_embeddings:\n",
    "    vecs = np.stack(image_embeddings[img])\n",
    "    image_embeddings[img] = np.mean(vecs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4dda8dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã sinh xong node embedding từ R-GCN và lưu model.\n"
     ]
    }
   ],
   "source": [
    "# 7. Lưu lại mô hình và embedding\n",
    "os.makedirs(\"saved_model_R_GCN\", exist_ok=True)\n",
    "with open(\"saved_model_R_GCN/image_embeddings.pkl\", \"wb\") as f:\n",
    "    pickle.dump(image_embeddings, f)\n",
    "with open(\"saved_model_R_GCN/node_label_encoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(le, f)\n",
    "torch.save(model.state_dict(), \"saved_model_R_GCN/rgcn_model_weights.pt\")\n",
    "\n",
    "print(\"Đã sinh xong node embedding từ R-GCN và lưu model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cda4b92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision@5: 0.3339\n",
      "Recall@5:    0.0061\n",
      "F1-score@5:  0.0114\n"
     ]
    }
   ],
   "source": [
    "# 8. Đánh giá Precision, Recall, F1-score\n",
    "entity_to_images = defaultdict(set)\n",
    "for _, row in df.iterrows():\n",
    "    entity_to_images[row['subject']].add(row['image_id'])\n",
    "    entity_to_images[row['predicate']].add(row['image_id'])\n",
    "    entity_to_images[row['object']].add(row['image_id'])\n",
    "\n",
    "ground_truth = defaultdict(set)\n",
    "for _, row in df.iterrows():\n",
    "    img_id = row['image_id']\n",
    "    related = entity_to_images[row['subject']] | entity_to_images[row['predicate']] | entity_to_images[row['object']]\n",
    "    related.discard(img_id)\n",
    "    ground_truth[img_id].update(related)\n",
    "\n",
    "image_ids = list(image_embeddings.keys())\n",
    "embedding_matrix = np.stack([image_embeddings[i] for i in image_ids])\n",
    "sim_matrix = cosine_similarity(embedding_matrix)\n",
    "\n",
    "predicted = {}\n",
    "for i, qid in enumerate(image_ids):\n",
    "    sims = sim_matrix[i]\n",
    "    sorted_idx = np.argsort(-sims)\n",
    "    top_ids = [image_ids[j] for j in sorted_idx if image_ids[j] != qid][:5]\n",
    "    predicted[qid] = top_ids\n",
    "\n",
    "def evaluate_retrieval(gt, pred, k=5):\n",
    "    precision, recall, f1 = [], [], []\n",
    "    for q in gt:\n",
    "        g = gt[q]\n",
    "        p = set(pred.get(q, [])[:k])\n",
    "        tp = len(g & p)\n",
    "        prec = tp / k\n",
    "        rec = tp / len(g) if g else 0\n",
    "        f1_score = 2 * prec * rec / (prec + rec) if prec + rec > 0 else 0\n",
    "        precision.append(prec)\n",
    "        recall.append(rec)\n",
    "        f1.append(f1_score)\n",
    "    return np.mean(precision), np.mean(recall), np.mean(f1)\n",
    "\n",
    "p, r, f1 = evaluate_retrieval(ground_truth, predicted, k=5)\n",
    "print(f\"\\nPrecision@5: {p:.4f}\\nRecall@5:    {r:.4f}\\nF1-score@5:  {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6d0b36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu toàn bộ: entity_encoder.pkl, node_embeddings.npy, entity_idx_to_images.pkl vào thư mục 'saved_models/'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# Tạo thư mục nếu chưa có\n",
    "output_dir = \"saved_model_R_GCN\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 1. Lưu LabelEncoder cho entity (node encoder)\n",
    "with open(os.path.join(output_dir, \"entity_encoder.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(le, f)  # le là LabelEncoder dùng cho all_nodes\n",
    "\n",
    "# 2. Lưu node embeddings\n",
    "np.save(os.path.join(output_dir, \"node_embeddings.npy\"), embeddings)\n",
    "\n",
    "# 3. Tạo entity_idx → danh sách ảnh (từ triplets)\n",
    "entity_idx_to_images = defaultdict(set)\n",
    "for s, p, o, img_id in triplets:\n",
    "    try:\n",
    "        s_id = le.transform([s])[0]\n",
    "        o_id = le.transform([o])[0]\n",
    "        entity_idx_to_images[s_id].add(img_id)\n",
    "        entity_idx_to_images[o_id].add(img_id)\n",
    "    except:\n",
    "        continue  # bỏ qua nếu không ánh xạ được\n",
    "\n",
    "# 4. Lưu entity_idx_to_images\n",
    "with open(os.path.join(output_dir, \"entity_idx_to_images.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(entity_idx_to_images, f)\n",
    "\n",
    "print(\"Đã lưu toàn bộ: entity_encoder.pkl, node_embeddings.npy, entity_idx_to_images.pkl vào thư mục 'saved_model_R_GCN/'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b55514d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Ước lượng Precision / Recall / F1-score R-GCN:\n",
      "{'Precision': 0.4444, 'Recall': 1.0, 'F1-score': 0.6154, 'Samples Used': 100}\n"
     ]
    }
   ],
   "source": [
    "results_prf = estimate_prf(top_k=5, random_k=5, sample_size=100)\n",
    "print(\"\\n Ước lượng Precision / Recall / F1-score R-GCN:\")\n",
    "print(results_prf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf7d9d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
