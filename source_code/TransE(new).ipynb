{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f012f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ƒê√£ ghi 3316 triplet v√†o transE_triplets.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load COCO\n",
    "coco = pd.read_csv(\"f_coco_triplets.csv\")\n",
    "\n",
    "# Ch·ªâ gi·ªØ c·ªôt c·∫ßn thi·∫øt\n",
    "coco = coco[[\"subject\", \"predicate\", \"object\"]]\n",
    "\n",
    "# Chu·∫©n ho√° text\n",
    "for col in [\"subject\", \"predicate\", \"object\"]:\n",
    "    coco[col] = coco[col].str.lower().str.strip()\n",
    "\n",
    "# L∆∞u ra file txt format cho PyKEEN\n",
    "coco.to_csv(\"transE_triplets.tsv\", sep=\"\\t\", index=False, header=False)\n",
    "\n",
    "print(f\"‚úÖ ƒê√£ ghi {len(coco)} triplet v√†o transE_triplets.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "272b7ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒê√£ chia th√†nh: 2652 train | 331 valid | 333 test\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# ƒê·ªçc to√†n b·ªô d√≤ng t·ª´ file g·ªëc\n",
    "with open('transE_triplets.tsv', 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# X√°o tr·ªôn th·ª© t·ª± d√≤ng ƒë·ªÉ tr√°nh thi√™n l·ªách\n",
    "random.shuffle(lines)\n",
    "\n",
    "# T√≠nh s·ªë l∆∞·ª£ng cho t·ª´ng t·∫≠p\n",
    "n_total = len(lines)\n",
    "n_train = int(0.8 * n_total)\n",
    "n_valid = int(0.1 * n_total)\n",
    "n_test = n_total - n_train - n_valid  # ph·∫ßn c√≤n l·∫°i\n",
    "\n",
    "# C·∫Øt theo t·ª∑ l·ªá\n",
    "train_lines = lines[:n_train]\n",
    "valid_lines = lines[n_train:n_train + n_valid]\n",
    "test_lines = lines[n_train + n_valid:]\n",
    "\n",
    "# Ghi ra c√°c file ri√™ng\n",
    "with open('train.tsv', 'w', encoding='utf-8') as f:\n",
    "    f.writelines(train_lines)\n",
    "\n",
    "with open('valid.tsv', 'w', encoding='utf-8') as f:\n",
    "    f.writelines(valid_lines)\n",
    "\n",
    "with open('test.tsv', 'w', encoding='utf-8') as f:\n",
    "    f.writelines(test_lines)\n",
    "\n",
    "print(f'ƒê√£ chia th√†nh: {len(train_lines)} train | {len(valid_lines)} valid | {len(test_lines)} test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6656e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed07d82aa0bf4d84b9c51d7c06d725dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cpu:   0%|          | 0/5 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/9 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/9 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/9 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/9 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/9 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03c4bd7eb8e84bc1bc9b0d84df372c64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cpu:   0%|          | 0.00/316 [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.90s seconds\n",
      "INFO:pykeen.stoppers.early_stopping:New best result at epoch 5: 538.302978515625. Saved model weights to C:\\Users\\admin\\.data\\pykeen\\checkpoints\\best-model-weights-1ee243a9-8c4c-4bc5-bdca-8350c262ea9d.pt\n",
      "INFO:pykeen.training.training_loop:=> Saved checkpoint after having finished epoch 5.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85b04bd2ef1d4b00b75904eca20927c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cpu:   0%|          | 0.00/312 [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.95s seconds\n"
     ]
    }
   ],
   "source": [
    "from pykeen.pipeline import pipeline\n",
    "from pykeen.triples import TriplesFactory\n",
    "\n",
    "# T·∫°o c√°c triples factory t·ª´ file\n",
    "train_tf = TriplesFactory.from_path('train.tsv', separator='\\t')\n",
    "valid_tf = TriplesFactory.from_path('valid.tsv', separator='\\t')\n",
    "test_tf = TriplesFactory.from_path('test.tsv', separator='\\t')\n",
    "\n",
    "# Kh·ªüi ch·∫°y pipeline hu·∫•n luy·ªán\n",
    "result = pipeline(\n",
    "    training=train_tf,\n",
    "    validation=valid_tf,\n",
    "    testing=test_tf,\n",
    "\n",
    "    model='TransE',\n",
    "    model_kwargs=dict(embedding_dim=100),\n",
    "\n",
    "    training_loop='slcwa',\n",
    "    optimizer='Adam',\n",
    "    optimizer_kwargs=dict(lr=1e-3),\n",
    "\n",
    "    stopper='early',\n",
    "    stopper_kwargs=dict(frequency=5, patience=10, metric='mean_rank'),\n",
    "\n",
    "    random_seed=42,\n",
    "    device='cpu' \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f25d3380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ƒê√£ l∆∞u embedding\n"
     ]
    }
   ],
   "source": [
    "# Entity embeddings\n",
    "entity_embeddings = result.model.entity_representations[0]().detach().cpu().numpy()\n",
    "entities = result.training.entity_to_id\n",
    "\n",
    "# Relation embeddings\n",
    "relation_embeddings = result.model.relation_representations[0]().detach().cpu().numpy()\n",
    "relations = result.training.relation_to_id\n",
    "\n",
    "# L∆∞u entity embedding\n",
    "import numpy as np\n",
    "np.save(\"entity_embeddings.npy\", entity_embeddings)\n",
    "with open(\"entities.txt\", \"w\", encoding='utf-8') as f:\n",
    "    for k, v in entities.items():\n",
    "        f.write(f\"{v}\\t{k}\\n\")\n",
    "\n",
    "# L∆∞u relation embedding\n",
    "np.save(\"relation_embeddings.npy\", relation_embeddings)\n",
    "with open(\"relations.txt\", \"w\", encoding='utf-8') as f:\n",
    "    for k, v in relations.items():\n",
    "        f.write(f\"{v}\\t{k}\\n\")\n",
    "\n",
    "print(\"‚úÖ ƒê√£ l∆∞u embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83878ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity2id = {}\n",
    "with open(\"entities.txt\", encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split(\"\\t\")\n",
    "        if len(parts) != 2:\n",
    "            continue  # b·ªè qua d√≤ng kh√¥ng h·ª£p l·ªá\n",
    "        idx, name = parts\n",
    "        entity2id[name] = int(idx)\n",
    "\n",
    "relation2id = {}\n",
    "with open(\"relations.txt\", encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split(\"\\t\")\n",
    "        if len(parts) != 2:\n",
    "            continue\n",
    "        idx, name = parts\n",
    "        relation2id[name] = int(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e62670bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ T·ªïng s·ªë triplet COCO: 3316\n",
      "     subject predicate  object  image_id source\n",
      "0        man      wear     hat     93437   coco\n",
      "1  telephone      have  banana     12667   coco\n",
      "2      group     drive    tree    314251   coco\n",
      "3        man     enjoy     nap    223747   coco\n",
      "4        man      wear     hat     93437   coco\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load v√† x·ª≠ l√Ω COCO\n",
    "triplet_map = pd.read_csv(\"f_coco_triplets.csv\").copy()\n",
    "triplet_map[\"source\"] = \"coco\"\n",
    "\n",
    "# Chu·∫©n h√≥a text\n",
    "triplet_map[[\"subject\", \"predicate\", \"object\"]] = triplet_map[[\"subject\", \"predicate\", \"object\"]].apply(\n",
    "    lambda x: x.str.lower().str.strip()\n",
    ")\n",
    "\n",
    "# N·∫øu b·∫°n v·∫´n mu·ªën d√πng t√™n bi·∫øn l√† `all_map`\n",
    "all_map = triplet_map\n",
    "\n",
    "# Ki·ªÉm tra nhanh\n",
    "print(f\"‚úÖ T·ªïng s·ªë triplet COCO: {len(all_map)}\")\n",
    "print(all_map.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95179837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå ƒêang t·∫°o vector cho t·∫•t c·∫£ triplet t·ª´ KG...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Nh√∫ng triplet truy v·∫•n\n",
    "def embed_triplet(head, rel, tail):\n",
    "    try:\n",
    "        h_id = entity2id[head]\n",
    "        r_id = relation2id[rel]\n",
    "        t_id = entity2id[tail]\n",
    "    except KeyError:\n",
    "        return None\n",
    "\n",
    "    h_vec = entity_embeddings[h_id]\n",
    "    r_vec = relation_embeddings[r_id]\n",
    "    t_vec = entity_embeddings[t_id]\n",
    "\n",
    "    score_vec = h_vec + r_vec - t_vec  # TransE scoring\n",
    "    return score_vec\n",
    "\n",
    "# T·∫°o embedding cho t·∫•t c·∫£ triplet trong KG\n",
    "def build_triplet_embedding_matrix(df):\n",
    "    triplet_vecs = []\n",
    "    valid_triplets = []\n",
    "    for _, row in df.iterrows():\n",
    "        trip = embed_triplet(row[\"subject\"], row[\"predicate\"], row[\"object\"])\n",
    "        if trip is not None:\n",
    "            triplet_vecs.append(trip)\n",
    "            valid_triplets.append((row[\"subject\"], row[\"predicate\"], row[\"object\"], row[\"image_id\"], row[\"source\"]))\n",
    "    return np.stack(triplet_vecs), valid_triplets\n",
    "\n",
    "print(\"üìå ƒêang t·∫°o vector cho t·∫•t c·∫£ triplet t·ª´ KG...\")\n",
    "triplet_matrix, triplet_info = build_triplet_embedding_matrix(all_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45f95efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_image_from_query(query_triplet, top_k=5):\n",
    "    query_vec = embed_triplet(*query_triplet)\n",
    "    if query_vec is None:\n",
    "        return []\n",
    "\n",
    "    sims = cosine_similarity(query_vec.reshape(1, -1), triplet_matrix)[0]\n",
    "    top_k_idx = sims.argsort()[::-1][:top_k]\n",
    "    results = [triplet_info[i] for i in top_k_idx]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d84135d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = (\"man\", \"riding\", \"horse\")\n",
    "results = find_nearest_image_from_query(query)\n",
    "\n",
    "for s, p, o, img_id, src in results:\n",
    "    print(f\"[{src}] image {img_id}: ({s}, {p}, {o})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f8c9184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√πng 500 triplet test t·ª´ COCO ƒë·ªÉ ƒë√°nh gi√°\n",
    "test_queries = all_map.drop_duplicates(subset=[\"subject\", \"predicate\", \"object\"]).sample(500, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63e7c199",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# T·∫°o dict: (s,p,o) ‚Üí t·∫≠p c√°c image_id th·ª±c s·ª± ch·ª©a triplet ƒë√≥\n",
    "gt_dict = defaultdict(set)\n",
    "\n",
    "for _, row in all_map.iterrows():\n",
    "    key = (row[\"subject\"], row[\"predicate\"], row[\"object\"])\n",
    "    gt_dict[key].add(str(row[\"image_id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92c1bc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_single_triplet(query, top_k=5):\n",
    "    results = find_nearest_image_from_query(query, top_k)\n",
    "    predicted_ids = {str(r[3]) for r in results}\n",
    "    true_ids = gt_dict.get(query, set())\n",
    "\n",
    "    if not true_ids:\n",
    "        return None  # kh√¥ng c√≥ ground truth ‚Üí b·ªè qua\n",
    "\n",
    "    tp = len(predicted_ids & true_ids)\n",
    "    fp = len(predicted_ids - true_ids)\n",
    "    fn = len(true_ids - predicted_ids)\n",
    "\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall    = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1        = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebb6e67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:01<00:00, 471.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Evaluation Results (top-5):\n",
      "‚Üí Precision@5: 0.2349\n",
      "‚Üí Recall@5:    0.9328\n",
      "‚Üí F1-score@5:  0.3602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "total_p, total_r, total_f1 = 0, 0, 0\n",
    "count = 0\n",
    "\n",
    "for _, row in tqdm(test_queries.iterrows(), total=len(test_queries)):\n",
    "    query = (row[\"subject\"], row[\"predicate\"], row[\"object\"])\n",
    "    result = evaluate_single_triplet(query, top_k=5)\n",
    "    if result:\n",
    "        p, r, f1 = result\n",
    "        total_p += p\n",
    "        total_r += r\n",
    "        total_f1 += f1\n",
    "        count += 1\n",
    "\n",
    "if count > 0:\n",
    "    print(\"üìä Evaluation Results (top-5):\")\n",
    "    print(f\"‚Üí Precision@5: {total_p/count:.4f}\")\n",
    "    print(f\"‚Üí Recall@5:    {total_r/count:.4f}\")\n",
    "    print(f\"‚Üí F1-score@5:  {total_f1/count:.4f}\")\n",
    "else:\n",
    "    print(\"‚ùå Kh√¥ng c√≥ truy v·∫•n n√†o c√≥ ground-truth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0620f56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
