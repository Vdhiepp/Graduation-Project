{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f012f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Đã ghi 3316 triplet vào transE_triplets.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load COCO\n",
    "coco = pd.read_csv(\"f_coco_triplets.csv\")\n",
    "\n",
    "# Chỉ giữ cột cần thiết\n",
    "coco = coco[[\"subject\", \"predicate\", \"object\"]]\n",
    "\n",
    "# Chuẩn hoá text\n",
    "for col in [\"subject\", \"predicate\", \"object\"]:\n",
    "    coco[col] = coco[col].str.lower().str.strip()\n",
    "\n",
    "# Lưu ra file txt format cho PyKEEN\n",
    "coco.to_csv(\"transE_triplets.tsv\", sep=\"\\t\", index=False, header=False)\n",
    "\n",
    "print(f\"✅ Đã ghi {len(coco)} triplet vào transE_triplets.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "272b7ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã chia thành: 2652 train | 331 valid | 333 test\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Đọc toàn bộ dòng từ file gốc\n",
    "with open('transE_triplets.tsv', 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Xáo trộn thứ tự dòng để tránh thiên lệch\n",
    "random.shuffle(lines)\n",
    "\n",
    "# Tính số lượng cho từng tập\n",
    "n_total = len(lines)\n",
    "n_train = int(0.8 * n_total)\n",
    "n_valid = int(0.1 * n_total)\n",
    "n_test = n_total - n_train - n_valid  # phần còn lại\n",
    "\n",
    "# Cắt theo tỷ lệ\n",
    "train_lines = lines[:n_train]\n",
    "valid_lines = lines[n_train:n_train + n_valid]\n",
    "test_lines = lines[n_train + n_valid:]\n",
    "\n",
    "# Ghi ra các file riêng\n",
    "with open('train.tsv', 'w', encoding='utf-8') as f:\n",
    "    f.writelines(train_lines)\n",
    "\n",
    "with open('valid.tsv', 'w', encoding='utf-8') as f:\n",
    "    f.writelines(valid_lines)\n",
    "\n",
    "with open('test.tsv', 'w', encoding='utf-8') as f:\n",
    "    f.writelines(test_lines)\n",
    "\n",
    "print(f'Đã chia thành: {len(train_lines)} train | {len(valid_lines)} valid | {len(test_lines)} test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6656e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed07d82aa0bf4d84b9c51d7c06d725dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epochs on cpu:   0%|          | 0/5 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/9 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/9 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/9 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/9 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training batches on cpu:   0%|          | 0/9 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03c4bd7eb8e84bc1bc9b0d84df372c64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cpu:   0%|          | 0.00/316 [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.90s seconds\n",
      "INFO:pykeen.stoppers.early_stopping:New best result at epoch 5: 538.302978515625. Saved model weights to C:\\Users\\admin\\.data\\pykeen\\checkpoints\\best-model-weights-1ee243a9-8c4c-4bc5-bdca-8350c262ea9d.pt\n",
      "INFO:pykeen.training.training_loop:=> Saved checkpoint after having finished epoch 5.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85b04bd2ef1d4b00b75904eca20927c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on cpu:   0%|          | 0.00/312 [00:00<?, ?triple/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 0.95s seconds\n"
     ]
    }
   ],
   "source": [
    "from pykeen.pipeline import pipeline\n",
    "from pykeen.triples import TriplesFactory\n",
    "\n",
    "# Tạo các triples factory từ file\n",
    "train_tf = TriplesFactory.from_path('train.tsv', separator='\\t')\n",
    "valid_tf = TriplesFactory.from_path('valid.tsv', separator='\\t')\n",
    "test_tf = TriplesFactory.from_path('test.tsv', separator='\\t')\n",
    "\n",
    "# Khởi chạy pipeline huấn luyện\n",
    "result = pipeline(\n",
    "    training=train_tf,\n",
    "    validation=valid_tf,\n",
    "    testing=test_tf,\n",
    "\n",
    "    model='TransE',\n",
    "    model_kwargs=dict(embedding_dim=100),\n",
    "\n",
    "    training_loop='slcwa',\n",
    "    optimizer='Adam',\n",
    "    optimizer_kwargs=dict(lr=1e-3),\n",
    "\n",
    "    stopper='early',\n",
    "    stopper_kwargs=dict(frequency=5, patience=10, metric='mean_rank'),\n",
    "\n",
    "    random_seed=42,\n",
    "    device='cpu' \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f25d3380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Đã lưu embedding\n"
     ]
    }
   ],
   "source": [
    "# Entity embeddings\n",
    "entity_embeddings = result.model.entity_representations[0]().detach().cpu().numpy()\n",
    "entities = result.training.entity_to_id\n",
    "\n",
    "# Relation embeddings\n",
    "relation_embeddings = result.model.relation_representations[0]().detach().cpu().numpy()\n",
    "relations = result.training.relation_to_id\n",
    "\n",
    "# Lưu entity embedding\n",
    "import numpy as np\n",
    "np.save(\"entity_embeddings.npy\", entity_embeddings)\n",
    "with open(\"entities.txt\", \"w\", encoding='utf-8') as f:\n",
    "    for k, v in entities.items():\n",
    "        f.write(f\"{v}\\t{k}\\n\")\n",
    "\n",
    "# Lưu relation embedding\n",
    "np.save(\"relation_embeddings.npy\", relation_embeddings)\n",
    "with open(\"relations.txt\", \"w\", encoding='utf-8') as f:\n",
    "    for k, v in relations.items():\n",
    "        f.write(f\"{v}\\t{k}\\n\")\n",
    "\n",
    "print(\"✅ Đã lưu embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83878ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity2id = {}\n",
    "with open(\"entities.txt\", encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split(\"\\t\")\n",
    "        if len(parts) != 2:\n",
    "            continue  # bỏ qua dòng không hợp lệ\n",
    "        idx, name = parts\n",
    "        entity2id[name] = int(idx)\n",
    "\n",
    "relation2id = {}\n",
    "with open(\"relations.txt\", encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split(\"\\t\")\n",
    "        if len(parts) != 2:\n",
    "            continue\n",
    "        idx, name = parts\n",
    "        relation2id[name] = int(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e62670bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tổng số triplet COCO: 3316\n",
      "     subject predicate  object  image_id source\n",
      "0        man      wear     hat     93437   coco\n",
      "1  telephone      have  banana     12667   coco\n",
      "2      group     drive    tree    314251   coco\n",
      "3        man     enjoy     nap    223747   coco\n",
      "4        man      wear     hat     93437   coco\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load và xử lý COCO\n",
    "triplet_map = pd.read_csv(\"f_coco_triplets.csv\").copy()\n",
    "triplet_map[\"source\"] = \"coco\"\n",
    "\n",
    "# Chuẩn hóa text\n",
    "triplet_map[[\"subject\", \"predicate\", \"object\"]] = triplet_map[[\"subject\", \"predicate\", \"object\"]].apply(\n",
    "    lambda x: x.str.lower().str.strip()\n",
    ")\n",
    "\n",
    "# Nếu bạn vẫn muốn dùng tên biến là `all_map`\n",
    "all_map = triplet_map\n",
    "\n",
    "# Kiểm tra nhanh\n",
    "print(f\"✅ Tổng số triplet COCO: {len(all_map)}\")\n",
    "print(all_map.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95179837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 Đang tạo vector cho tất cả triplet từ KG...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Nhúng triplet truy vấn\n",
    "def embed_triplet(head, rel, tail):\n",
    "    try:\n",
    "        h_id = entity2id[head]\n",
    "        r_id = relation2id[rel]\n",
    "        t_id = entity2id[tail]\n",
    "    except KeyError:\n",
    "        return None\n",
    "\n",
    "    h_vec = entity_embeddings[h_id]\n",
    "    r_vec = relation_embeddings[r_id]\n",
    "    t_vec = entity_embeddings[t_id]\n",
    "\n",
    "    score_vec = h_vec + r_vec - t_vec  # TransE scoring\n",
    "    return score_vec\n",
    "\n",
    "# Tạo embedding cho tất cả triplet trong KG\n",
    "def build_triplet_embedding_matrix(df):\n",
    "    triplet_vecs = []\n",
    "    valid_triplets = []\n",
    "    for _, row in df.iterrows():\n",
    "        trip = embed_triplet(row[\"subject\"], row[\"predicate\"], row[\"object\"])\n",
    "        if trip is not None:\n",
    "            triplet_vecs.append(trip)\n",
    "            valid_triplets.append((row[\"subject\"], row[\"predicate\"], row[\"object\"], row[\"image_id\"], row[\"source\"]))\n",
    "    return np.stack(triplet_vecs), valid_triplets\n",
    "\n",
    "print(\"📌 Đang tạo vector cho tất cả triplet từ KG...\")\n",
    "triplet_matrix, triplet_info = build_triplet_embedding_matrix(all_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45f95efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_image_from_query(query_triplet, top_k=5):\n",
    "    query_vec = embed_triplet(*query_triplet)\n",
    "    if query_vec is None:\n",
    "        return []\n",
    "\n",
    "    sims = cosine_similarity(query_vec.reshape(1, -1), triplet_matrix)[0]\n",
    "    top_k_idx = sims.argsort()[::-1][:top_k]\n",
    "    results = [triplet_info[i] for i in top_k_idx]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d84135d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = (\"man\", \"riding\", \"horse\")\n",
    "results = find_nearest_image_from_query(query)\n",
    "\n",
    "for s, p, o, img_id, src in results:\n",
    "    print(f\"[{src}] image {img_id}: ({s}, {p}, {o})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f8c9184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dùng 500 triplet test từ COCO để đánh giá\n",
    "test_queries = all_map.drop_duplicates(subset=[\"subject\", \"predicate\", \"object\"]).sample(500, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63e7c199",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Tạo dict: (s,p,o) → tập các image_id thực sự chứa triplet đó\n",
    "gt_dict = defaultdict(set)\n",
    "\n",
    "for _, row in all_map.iterrows():\n",
    "    key = (row[\"subject\"], row[\"predicate\"], row[\"object\"])\n",
    "    gt_dict[key].add(str(row[\"image_id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92c1bc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_single_triplet(query, top_k=5):\n",
    "    results = find_nearest_image_from_query(query, top_k)\n",
    "    predicted_ids = {str(r[3]) for r in results}\n",
    "    true_ids = gt_dict.get(query, set())\n",
    "\n",
    "    if not true_ids:\n",
    "        return None  # không có ground truth → bỏ qua\n",
    "\n",
    "    tp = len(predicted_ids & true_ids)\n",
    "    fp = len(predicted_ids - true_ids)\n",
    "    fn = len(true_ids - predicted_ids)\n",
    "\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall    = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1        = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebb6e67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 500/500 [00:01<00:00, 471.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Evaluation Results (top-5):\n",
      "→ Precision@5: 0.2349\n",
      "→ Recall@5:    0.9328\n",
      "→ F1-score@5:  0.3602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "total_p, total_r, total_f1 = 0, 0, 0\n",
    "count = 0\n",
    "\n",
    "for _, row in tqdm(test_queries.iterrows(), total=len(test_queries)):\n",
    "    query = (row[\"subject\"], row[\"predicate\"], row[\"object\"])\n",
    "    result = evaluate_single_triplet(query, top_k=5)\n",
    "    if result:\n",
    "        p, r, f1 = result\n",
    "        total_p += p\n",
    "        total_r += r\n",
    "        total_f1 += f1\n",
    "        count += 1\n",
    "\n",
    "if count > 0:\n",
    "    print(\"📊 Evaluation Results (top-5):\")\n",
    "    print(f\"→ Precision@5: {total_p/count:.4f}\")\n",
    "    print(f\"→ Recall@5:    {total_r/count:.4f}\")\n",
    "    print(f\"→ F1-score@5:  {total_f1/count:.4f}\")\n",
    "else:\n",
    "    print(\"❌ Không có truy vấn nào có ground-truth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0620f56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
