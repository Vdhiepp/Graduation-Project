{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7362d89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import dgl\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch.nn as nn\n",
    "from dgl.nn import GraphConv\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "\n",
    "# 1. Đọc dữ liệu và tạo đồ thị NetworkX\n",
    "df = pd.read_csv('f_coco_triplets.csv').dropna().astype(str)\n",
    "triplets = list(zip(df['subject'], df['predicate'], df['object'], df['image_id']))\n",
    "\n",
    "G = nx.DiGraph()\n",
    "for s, p, o, img_id in triplets:\n",
    "    mid_node = f\"{s}_{p}_{o}\"\n",
    "    G.add_edge(s, mid_node, relation=p)\n",
    "    G.add_edge(mid_node, o, relation=p)\n",
    "    G.nodes[mid_node]['image_id'] = img_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bff1ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Chuyển sang đồ thị DGL\n",
    "all_nodes = list(G.nodes)\n",
    "le = LabelEncoder()\n",
    "node_ids = le.fit_transform(all_nodes)\n",
    "node_id_map = dict(zip(all_nodes, node_ids))\n",
    "\n",
    "src = [node_id_map[u] for u, v in G.edges()]\n",
    "dst = [node_id_map[v] for u, v in G.edges()]\n",
    "g = dgl.graph((src, dst))\n",
    "g = dgl.add_self_loop(g)\n",
    "features = torch.eye(len(all_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cba76b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Gán nhãn: node_mid → label = image_id\n",
    "node_labels = -1 * np.ones(len(all_nodes), dtype=np.int32)\n",
    "image_id_set = sorted({G.nodes[n]['image_id'] for n in G.nodes if 'image_id' in G.nodes[n]})\n",
    "image_id_encoder = LabelEncoder().fit(image_id_set)\n",
    "\n",
    "for node in G.nodes:\n",
    "    if 'image_id' in G.nodes[node]:\n",
    "        idx = node_id_map[node]\n",
    "        label = image_id_encoder.transform([G.nodes[node]['image_id']])[0]\n",
    "        node_labels[idx] = label\n",
    "\n",
    "labels = torch.tensor(node_labels, dtype=torch.long)\n",
    "mask = labels != -1  # chỉ train các node có image_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f2c726a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Định nghĩa mô hình GCN\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, out_feats):\n",
    "        super().__init__()\n",
    "        self.conv1 = GraphConv(in_feats, h_feats)\n",
    "        self.conv2 = GraphConv(h_feats, out_feats)\n",
    "\n",
    "    def forward(self, g, x):\n",
    "        x = self.conv1(g, x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(g, x)\n",
    "        return x\n",
    "\n",
    "num_classes = len(image_id_encoder.classes_)\n",
    "model = GCN(features.shape[1], 64, num_classes)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf80ad97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss: 0.0356\n",
      "Epoch 10 | Loss: 0.0257\n",
      "Epoch 20 | Loss: 0.0205\n",
      "Epoch 30 | Loss: 0.0172\n",
      "Epoch 40 | Loss: 0.0149\n",
      "Epoch 50 | Loss: 0.0131\n",
      "Epoch 60 | Loss: 0.0117\n",
      "Epoch 70 | Loss: 0.0105\n",
      "Epoch 80 | Loss: 0.0095\n",
      "Epoch 90 | Loss: 0.0087\n",
      "Epoch 100 | Loss: 0.0080\n",
      "Epoch 110 | Loss: 0.0073\n",
      "Epoch 120 | Loss: 0.0068\n",
      "Epoch 130 | Loss: 0.0063\n",
      "Epoch 140 | Loss: 0.0059\n",
      "Epoch 150 | Loss: 0.0055\n",
      "Epoch 160 | Loss: 0.0051\n",
      "Epoch 170 | Loss: 0.0048\n",
      "Epoch 180 | Loss: 0.0045\n",
      "Epoch 190 | Loss: 0.0043\n"
     ]
    }
   ],
   "source": [
    "# 5. Huấn luyện mô hình\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    out = model(g, features)\n",
    "    loss = F.cross_entropy(out[mask], labels[mask])\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch} | Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe0847d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Trích node embedding sau huấn luyện\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    node_embeddings = model(g, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ed1eb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Tính embedding trung bình mỗi ảnh\n",
    "embeddings = node_embeddings.numpy()\n",
    "image_embeddings = defaultdict(list)\n",
    "\n",
    "for node, idx in node_id_map.items():\n",
    "    if 'image_id' in G.nodes[node]:\n",
    "        img_id = G.nodes[node]['image_id']\n",
    "        image_embeddings[img_id].append(embeddings[idx])\n",
    "\n",
    "for img in image_embeddings:\n",
    "    vecs = np.stack(image_embeddings[img])\n",
    "    image_embeddings[img] = np.mean(vecs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71f41c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã huấn luyện xong GCN và lưu toàn bộ embedding.\n"
     ]
    }
   ],
   "source": [
    "# 8. Lưu kết quả\n",
    "os.makedirs(\"saved_model_GCN\", exist_ok=True)\n",
    "\n",
    "torch.save(model.state_dict(), \"saved_model_GCN/gcn_model_weights.pt\")\n",
    "np.save(\"saved_model_GCN/node_embeddings.npy\", node_embeddings.numpy())\n",
    "with open(\"saved_model_GCN/image_embeddings.pkl\", \"wb\") as f:\n",
    "    pickle.dump(image_embeddings, f)\n",
    "with open(\"saved_model_GCN/node_label_encoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(le, f)\n",
    "\n",
    "print(\"Đã huấn luyện xong GCN và lưu toàn bộ embedding.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "638b3eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Tạo và lưu entity_encoder (dành cho tìm kiếm ảnh theo triplet caption) ===\n",
    "entities = pd.unique(df[['subject', 'object']].values.ravel())\n",
    "entity_encoder = LabelEncoder().fit(entities)\n",
    "\n",
    "# Tạo entity_idx_to_images\n",
    "entity_idx_to_images = defaultdict(list)\n",
    "for s, p, o, img_id in triplets:\n",
    "    for e in [s, o]:\n",
    "        try:\n",
    "            idx = entity_encoder.transform([e])[0]\n",
    "            entity_idx_to_images[idx].append(int(img_id))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "# === Lưu thêm 3 file cần cho tìm kiếm caption ===\n",
    "with open(\"saved_model_GCN/entity_encoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(entity_encoder, f)\n",
    "\n",
    "with open(\"saved_model_GCN/entity_idx_to_images.pkl\", \"wb\") as f:\n",
    "    pickle.dump(entity_idx_to_images, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695c0f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e021794e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Đọc file triplet\n",
    "df = pd.read_csv(\"f_coco_triplets.csv\").dropna().astype(str)\n",
    "\n",
    "# Ground-truth: ảnh nào chia sẻ subject/predicate/object thì coi là \"liên quan\"\n",
    "entity_to_images = defaultdict(set)\n",
    "for _, row in df.iterrows():\n",
    "    entity_to_images[row[\"subject\"]].add(row[\"image_id\"])\n",
    "    entity_to_images[row[\"predicate\"]].add(row[\"image_id\"])\n",
    "    entity_to_images[row[\"object\"]].add(row[\"image_id\"])\n",
    "\n",
    "# Mỗi ảnh → các ảnh liên quan (ground truth)\n",
    "ground_truth = defaultdict(set)\n",
    "for _, row in df.iterrows():\n",
    "    img_id = row[\"image_id\"]\n",
    "    related_imgs = entity_to_images[row[\"subject\"]] | entity_to_images[row[\"predicate\"]] | entity_to_images[row[\"object\"]]\n",
    "    related_imgs.discard(img_id)  # Không tính chính nó\n",
    "    ground_truth[img_id].update(related_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e2c457f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Đọc embedding ảnh từ file đã lưu\n",
    "with open(\"saved_model_GCN/image_embeddings.pkl\", \"rb\") as f:\n",
    "    image_embeddings = pickle.load(f)\n",
    "\n",
    "image_ids = list(image_embeddings.keys())\n",
    "embedding_matrix = np.stack([image_embeddings[img_id] for img_id in image_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c8c3e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = {}\n",
    "\n",
    "similarity_matrix = cosine_similarity(embedding_matrix)\n",
    "\n",
    "for i, query_id in enumerate(image_ids):\n",
    "    sim_scores = similarity_matrix[i]\n",
    "    # Sắp xếp và lấy top ảnh (loại bỏ chính nó)\n",
    "    sorted_idx = np.argsort(-sim_scores)\n",
    "    top_imgs = [image_ids[j] for j in sorted_idx if image_ids[j] != query_id][:5]\n",
    "    predicted[query_id] = top_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "197a3a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@5: 0.6493\n",
      "Recall@5:    0.0364\n",
      "F1-score@5:  0.0594\n"
     ]
    }
   ],
   "source": [
    "def evaluate_image_retrieval(ground_truth, predicted, top_k=5):\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    f1_list = []\n",
    "\n",
    "    for query_id in ground_truth:\n",
    "        gt_set = ground_truth[query_id]\n",
    "        pred_list = predicted.get(query_id, [])[:top_k]\n",
    "        pred_set = set(pred_list)\n",
    "\n",
    "        true_positive = len(gt_set & pred_set)\n",
    "        precision = true_positive / len(pred_list) if pred_list else 0.0\n",
    "        recall = true_positive / len(gt_set) if gt_set else 0.0\n",
    "        f1 = (2 * precision * recall / (precision + recall)) if precision + recall > 0 else 0.0\n",
    "\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1_list.append(f1)\n",
    "\n",
    "    precision_avg = sum(precision_list) / len(precision_list)\n",
    "    recall_avg = sum(recall_list) / len(recall_list)\n",
    "    f1_avg = sum(f1_list) / len(f1_list)\n",
    "\n",
    "    return precision_avg, recall_avg, f1_avg\n",
    "\n",
    "# ✅ Gọi hàm đánh giá\n",
    "p, r, f1 = evaluate_image_retrieval(ground_truth, predicted, top_k=5)\n",
    "print(f\"Precision@5: {p:.4f}\")\n",
    "print(f\"Recall@5:    {r:.4f}\")\n",
    "print(f\"F1-score@5:  {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d6560d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
