{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a68c332",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing captions: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25014/25014 [04:01<00:00, 103.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÄÃ£ lÆ°u 2161 dÃ²ng triplet vÃ o filtered_triplets.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Load NLP ===\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# === Load COCO Captions ===\n",
    "with open(\"E:/Download/annotations/captions_val2017.json\", \"r\") as f:\n",
    "    captions_data = json.load(f)[\"annotations\"]\n",
    "\n",
    "# === Load COCO Instances ===\n",
    "with open(\"E:/Download/annotations/instances_val2017.json\", \"r\") as f:\n",
    "    instances_all = json.load(f)\n",
    "    instances_data = instances_all[\"annotations\"]\n",
    "    category_map = {cat[\"id\"]: cat[\"name\"] for cat in instances_all[\"categories\"]}\n",
    "\n",
    "# === Build image_id â†’ set of object names ===\n",
    "image_objects = defaultdict(set)\n",
    "for inst in instances_data:\n",
    "    cat_name = category_map[inst[\"category_id\"]]\n",
    "    image_objects[inst[\"image_id\"]].add(cat_name.lower())\n",
    "\n",
    "# === HÃ m trÃ­ch triplet tá»« caption báº±ng spaCy ===\n",
    "def extract_triplets(caption):\n",
    "    doc = nlp(caption)\n",
    "    triplets = []\n",
    "    for sent in doc.sents:\n",
    "        subject, predicate, obj = None, None, None\n",
    "        for token in sent:\n",
    "            if token.dep_ == \"nsubj\" and token.head.pos_ == \"VERB\":\n",
    "                subject = token.text.lower()\n",
    "                predicate = token.head.text.lower()\n",
    "                for child in token.head.children:\n",
    "                    if child.dep_ in (\"dobj\", \"attr\", \"prep\", \"pobj\") and child.pos_ in (\"NOUN\", \"PRON\"):\n",
    "                        obj = child.text.lower()\n",
    "                        break\n",
    "        if subject and predicate:\n",
    "            triplets.append((subject, predicate, obj))\n",
    "    return triplets\n",
    "\n",
    "# === Xá»­ lÃ½ toÃ n bá»™ caption Ä‘á»ƒ lá»c triplet há»£p lá»‡ ===\n",
    "filtered_rows = []\n",
    "for item in tqdm(captions_data, desc=\"Processing captions\"):\n",
    "    img_id = item[\"image_id\"]\n",
    "    caption = item[\"caption\"]\n",
    "    triplets = extract_triplets(caption)\n",
    "    valid_objects = image_objects.get(img_id, set())\n",
    "    \n",
    "    for subj, pred, obj in triplets:\n",
    "        if subj in valid_objects or obj in valid_objects:\n",
    "            filtered_rows.append({\n",
    "                \"subject\": subj,\n",
    "                \"predicate\": pred,\n",
    "                \"object\": obj,\n",
    "                \"image_id\": img_id,\n",
    "                \"caption\": caption\n",
    "            })\n",
    "\n",
    "# === Xuáº¥t ra file CSV ===\n",
    "df = pd.DataFrame(filtered_rows)\n",
    "df.to_csv(\"filtered_triplets.csv\", index=False)\n",
    "print(f\"ÄÃ£ lÆ°u {len(df)} dÃ²ng triplet vÃ o filtered_triplets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73aeaf72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tá»•ng sá»‘ áº£nh cÃ³ cáº£ caption vÃ  object: 4952\n",
      "Chá»n image_id há»£p lá»‡: 458755\n"
     ]
    }
   ],
   "source": [
    "# Danh sÃ¡ch áº£nh cÃ³ caption\n",
    "caption_ids = set([cap[\"image_id\"] for cap in captions_data])\n",
    "\n",
    "# Danh sÃ¡ch áº£nh cÃ³ object (annotation)\n",
    "instance_ids = set(image_objects.keys())\n",
    "\n",
    "# Láº¥y áº£nh cÃ³ cáº£ caption vÃ  object\n",
    "valid_ids = caption_ids & instance_ids\n",
    "print(f\"Tá»•ng sá»‘ áº£nh cÃ³ cáº£ caption vÃ  object: {len(valid_ids)}\")\n",
    "\n",
    "# Láº¥y má»™t vÃ­ dá»¥ há»£p lá»‡ (cÃ³ thá»ƒ thay Ä‘á»•i)\n",
    "test_image_id = list(valid_ids)[0]\n",
    "print(f\"Chá»n image_id há»£p lá»‡: {test_image_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28f0909e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependency parsing result:\n",
      "\n",
      "Token       POS     Dep         Head        \n",
      "--------------------------------------------\n",
      "Young       ADJ     amod        woman       \n",
      "woman       NOUN    ROOT        woman       \n",
      "with        ADP     prep        woman       \n",
      "sheep       NOUN    pobj        with        \n",
      "on          ADP     prep        sheep       \n",
      "straw       NOUN    npadvmod    covered     \n",
      "covered     VERB    amod        floor       \n",
      "floor       NOUN    pobj        on          \n"
     ]
    }
   ],
   "source": [
    "caption = \"Young woman with sheep on straw covered floor\"\n",
    "doc = nlp(caption)\n",
    "\n",
    "print(\"Dependency parsing result:\\n\")\n",
    "print(f\"{'Token':<12}{'POS':<8}{'Dep':<12}{'Head':<12}\")\n",
    "print(\"-\" * 44)\n",
    "for token in doc:\n",
    "    print(f\"{token.text:<12}{token.pos_:<8}{token.dep_:<12}{token.head.text:<12}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3c6a66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependency parsing result:\n",
      "\n",
      "Token       POS     Dep         Head        \n",
      "--------------------------------------------\n",
      "A           DET     det         child       \n",
      "child       NOUN    nsubj       places      \n",
      "places      VERB    ROOT        places      \n",
      "his         PRON    poss        hands       \n",
      "hands       NOUN    dobj        places      \n",
      "on          ADP     prep        places      \n",
      "the         DET     det         head        \n",
      "head        NOUN    pobj        on          \n",
      "and         CCONJ   cc          head        \n",
      "neck        NOUN    conj        head        \n",
      "of          ADP     prep        head        \n",
      "a           DET     det         sheep       \n",
      "sheep       NOUN    pobj        of          \n",
      "while       SCONJ   mark        looks       \n",
      "another     DET     det         sheep       \n",
      "sheep       NOUN    nsubj       looks       \n",
      "looks       VERB    advcl       places      \n",
      "at          ADP     prep        looks       \n",
      "his         PRON    poss        face        \n",
      "face        NOUN    pobj        at          \n"
     ]
    }
   ],
   "source": [
    "caption = \"A child places his hands on the head and neck of a sheep while another sheep looks at his face\"\n",
    "doc = nlp(caption)\n",
    "\n",
    "print(\"Dependency parsing result:\\n\")\n",
    "print(f\"{'Token':<12}{'POS':<8}{'Dep':<12}{'Head':<12}\")\n",
    "print(\"-\" * 44)\n",
    "for token in doc:\n",
    "    print(f\"{token.text:<12}{token.pos_:<8}{token.dep_:<12}{token.head.text:<12}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53dfd998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependency parsing result:\n",
      "\n",
      "Token       POS     Dep         Head        \n",
      "--------------------------------------------\n",
      "A           DET     det         person      \n",
      "person      NOUN    ROOT        person      \n",
      "petting     VERB    acl         person      \n",
      "the         DET     det         head        \n",
      "head        NOUN    dobj        petting     \n",
      "of          ADP     prep        head        \n",
      "a           DET     det         sheep       \n",
      "cute        ADJ     amod        sheep       \n",
      "fluffy      ADJ     amod        sheep       \n",
      "sheep       NOUN    pobj        of          \n"
     ]
    }
   ],
   "source": [
    "caption = \"A person petting the head of a cute fluffy sheep\"\n",
    "doc = nlp(caption)\n",
    "\n",
    "print(\"Dependency parsing result:\\n\")\n",
    "print(f\"{'Token':<12}{'POS':<8}{'Dep':<12}{'Head':<12}\")\n",
    "print(\"-\" * 44)\n",
    "for token in doc:\n",
    "    print(f\"{token.text:<12}{token.pos_:<8}{token.dep_:<12}{token.head.text:<12}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ec87fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependency parsing result:\n",
      "\n",
      "Token       POS     Dep         Head        \n",
      "--------------------------------------------\n",
      "A           DET     det         child       \n",
      "child       NOUN    nsubj       petting     \n",
      "is          AUX     aux         petting     \n",
      "petting     VERB    ROOT        petting     \n",
      "a           DET     det         sheep       \n",
      "sheep       NOUN    dobj        petting     \n",
      "while       SCONJ   mark        watches     \n",
      "another     DET     det         sheep       \n",
      "sheep       NOUN    nsubj       watches     \n",
      "watches     VERB    advcl       petting     \n"
     ]
    }
   ],
   "source": [
    "caption = \"A child is petting a sheep while another sheep watches\"\n",
    "doc = nlp(caption)\n",
    "\n",
    "print(\"Dependency parsing result:\\n\")\n",
    "print(f\"{'Token':<12}{'POS':<8}{'Dep':<12}{'Head':<12}\")\n",
    "print(\"-\" * 44)\n",
    "for token in doc:\n",
    "    print(f\"{token.text:<12}{token.pos_:<8}{token.dep_:<12}{token.head.text:<12}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f69c649c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependency parsing result:\n",
      "\n",
      "Token       POS     Dep         Head        \n",
      "--------------------------------------------\n",
      "A           DET     det         woman       \n",
      "woman       NOUN    ROOT        woman       \n",
      "kneeling    VERB    acl         woman       \n",
      "to          ADP     prep        kneeling    \n",
      "pet         ADJ     amod        animals     \n",
      "animals     NOUN    pobj        to          \n",
      "while       SCONJ   mark        wait        \n",
      "others      NOUN    nsubj       wait        \n",
      "wait        VERB    advcl       woman       \n"
     ]
    }
   ],
   "source": [
    "caption = \"A woman kneeling to pet animals while others wait\"\n",
    "doc = nlp(caption)\n",
    "\n",
    "print(\"Dependency parsing result:\\n\")\n",
    "print(f\"{'Token':<12}{'POS':<8}{'Dep':<12}{'Head':<12}\")\n",
    "print(\"-\" * 44)\n",
    "for token in doc:\n",
    "    print(f\"{token.text:<12}{token.pos_:<8}{token.dep_:<12}{token.head.text:<12}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "91468611",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_triplets(caption):\n",
    "    doc = nlp(caption)\n",
    "    triplets = []\n",
    "\n",
    "    for sent in doc.sents:\n",
    "        # 1. subject - verb - object\n",
    "        for token in sent:\n",
    "            if token.dep_ == \"nsubj\" and token.head.pos_ == \"VERB\":\n",
    "                subject = token.text.lower()\n",
    "                predicate = token.head.text.lower()\n",
    "                obj = None\n",
    "                for child in token.head.children:\n",
    "                    if child.dep_ in (\"dobj\", \"attr\") and child.pos_ in (\"NOUN\", \"PRON\"):\n",
    "                        obj = child.text.lower()\n",
    "                        triplets.append((subject, predicate, obj))\n",
    "                    elif child.dep_ == \"prep\":\n",
    "                        pobj = next((t for t in child.children if t.dep_ == \"pobj\"), None)\n",
    "                        if pobj:\n",
    "                            if obj:\n",
    "                                triplets.append((obj, child.text.lower(), pobj.text.lower()))\n",
    "                                for conj in pobj.children:\n",
    "                                    if conj.dep_ == \"conj\":\n",
    "                                        triplets.append((obj, child.text.lower(), conj.text.lower()))\n",
    "                            else:\n",
    "                                triplets.append((subject, predicate, pobj.text.lower()))\n",
    "\n",
    "        # 2. noun - prep - noun\n",
    "        for token in sent:\n",
    "            if token.dep_ == \"prep\" and token.head.pos_ == \"NOUN\":\n",
    "                pobj = next((child for child in token.children if child.dep_ == \"pobj\"), None)\n",
    "                if pobj:\n",
    "                    triplets.append((token.head.text.lower(), token.text.lower(), pobj.text.lower()))\n",
    "                    for conj in pobj.children:\n",
    "                        if conj.dep_ == \"conj\":\n",
    "                            triplets.append((token.head.text.lower(), token.text.lower(), conj.text.lower()))\n",
    "\n",
    "        # 3. noun - and - noun\n",
    "        for token in sent:\n",
    "            if token.dep_ == \"conj\" and token.head.pos_ == \"NOUN\":\n",
    "                for parent in token.head.children:\n",
    "                    if parent.dep_ in (\"det\", \"amod\"):\n",
    "                        triplets.append((token.head.text.lower(), \"and\", token.text.lower()))\n",
    "\n",
    "        # 4. amod verb + npadvmod\n",
    "        for token in sent:\n",
    "            if token.dep_ == \"amod\" and token.head.pos_ == \"NOUN\" and token.pos_ == \"VERB\":\n",
    "                modifier = next((child for child in token.children if child.dep_ == \"npadvmod\"), None)\n",
    "                if modifier:\n",
    "                    triplets.append((token.head.text.lower(), token.text.lower(), modifier.text.lower()))\n",
    "\n",
    "        # 5. tÃ­nh tá»« bá»• nghÄ©a cho danh tá»« (e.g., fluffy sheep)\n",
    "        for token in sent:\n",
    "            if token.dep_ == \"amod\" and token.head.pos_ == \"NOUN\":\n",
    "                triplets.append((token.head.text.lower(), \"amod\", token.text.lower()))\n",
    "\n",
    "        # 6. advcl (e.g., while others wait)\n",
    "        for token in sent:\n",
    "            if token.dep_ == \"advcl\" and token.pos_ == \"VERB\":\n",
    "                verb = token.text.lower()\n",
    "                subject = None\n",
    "                obj = None\n",
    "                for child in token.children:\n",
    "                    if child.dep_ == \"nsubj\":\n",
    "                        subject = child.text.lower()\n",
    "                    elif child.dep_ in (\"dobj\", \"attr\", \"pobj\") and child.pos_ == \"NOUN\":\n",
    "                        obj = child.text.lower()\n",
    "                if subject:\n",
    "                    triplets.append((subject, verb, obj))\n",
    "\n",
    "        # 7. acl + to + amod/xcomp â†’ chuyá»ƒn Ä‘á»™ng tá»« bá»• sung\n",
    "        for token in sent:\n",
    "            if token.pos_ == \"VERB\" and token.dep_ == \"acl\":\n",
    "                subj = token.head.text.lower()\n",
    "                verb1 = token.text.lower()\n",
    "                triplets.append((subj, verb1, None))\n",
    "\n",
    "                for child in token.children:\n",
    "                    if child.dep_ == \"prep\" and child.text.lower() == \"to\":\n",
    "                        for grandchild in child.children:\n",
    "                            if grandchild.dep_ in (\"amod\", \"xcomp\") and grandchild.head.pos_ == \"NOUN\":\n",
    "                                triplets.append((subj, grandchild.text.lower(), grandchild.head.text.lower()))\n",
    "\n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "43ab8b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“¸ Testing image_id = 458755\n",
      "\n",
      "ðŸ“Œ Caption 1: Young woman with sheep on straw covered floor.\n",
      "   â†’ Triplet: ('woman', 'with', 'sheep')\n",
      "   â†’ Triplet: ('sheep', 'on', 'floor')\n",
      "   â†’ Triplet: ('floor', 'covered', 'straw')\n",
      "   â†’ Triplet: ('woman', 'amod', 'young')\n",
      "   â†’ Triplet: ('floor', 'amod', 'covered')\n",
      "\n",
      "ðŸ“Œ Caption 2: A child places his hands on the head and neck of a sheep while another sheep looks at his face.\n",
      "   â†’ Triplet: ('child', 'places', 'hands')\n",
      "   â†’ Triplet: ('hands', 'on', 'head')\n",
      "   â†’ Triplet: ('hands', 'on', 'neck')\n",
      "   â†’ Triplet: ('sheep', 'looks', 'face')\n",
      "   â†’ Triplet: ('head', 'of', 'sheep')\n",
      "   â†’ Triplet: ('head', 'and', 'neck')\n",
      "   â†’ Triplet: ('sheep', 'looks', None)\n",
      "\n",
      "ðŸ“Œ Caption 3: A person petting the head of a cute fluffy sheep.\n",
      "   â†’ Triplet: ('head', 'of', 'sheep')\n",
      "   â†’ Triplet: ('sheep', 'amod', 'cute')\n",
      "   â†’ Triplet: ('sheep', 'amod', 'fluffy')\n",
      "   â†’ Triplet: ('person', 'petting', None)\n",
      "\n",
      "ðŸ“Œ Caption 4: A child is petting a sheep while another sheep watches.\n",
      "   â†’ Triplet: ('child', 'petting', 'sheep')\n",
      "   â†’ Triplet: ('sheep', 'watches', None)\n",
      "\n",
      "ðŸ“Œ Caption 5: A woman kneeling to pet animals while others wait. \n",
      "   â†’ Triplet: ('animals', 'amod', 'pet')\n",
      "   â†’ Triplet: ('others', 'wait', None)\n",
      "   â†’ Triplet: ('woman', 'kneeling', None)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# ÄÆ°á»ng dáº«n tá»›i file caption COCO (báº¡n chá»‰nh náº¿u cáº§n)\n",
    "caption_file = \"E:/Download/annotations/captions_val2017.json\"\n",
    "\n",
    "# Load caption tá»« file JSON\n",
    "with open(caption_file, \"r\") as f:\n",
    "    caption_data = json.load(f)[\"annotations\"]\n",
    "\n",
    "# ID cáº§n kiá»ƒm thá»­\n",
    "test_image_id = 458755\n",
    "\n",
    "# Láº¥y 5 caption cá»§a áº£nh nÃ y\n",
    "captions = [item[\"caption\"] for item in caption_data if item[\"image_id\"] == test_image_id]\n",
    "\n",
    "# Kiá»ƒm thá»­ báº±ng extract_triplets()\n",
    "print(f\"\\nðŸ“¸ Testing image_id = {test_image_id}\")\n",
    "for i, caption in enumerate(captions, 1):\n",
    "    print(f\"\\nðŸ“Œ Caption {i}: {caption}\")\n",
    "    triplets = extract_triplets(caption)\n",
    "    if not triplets:\n",
    "        print(\"   â†’ âŒ KhÃ´ng trÃ­ch Ä‘Æ°á»£c triplet nÃ o.\")\n",
    "    else:\n",
    "        for trip in triplets:\n",
    "            print(\"   â†’ Triplet:\", trip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "372a2b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_triplets(caption):\n",
    "    doc = nlp(caption)\n",
    "    triplets = []\n",
    "\n",
    "    for sent in doc.sents:\n",
    "        # 1. subject - verb - object\n",
    "        for token in sent:\n",
    "            if token.dep_ == \"nsubj\" and token.head.pos_ == \"VERB\":\n",
    "                subject = token.text.lower()\n",
    "                predicate = token.head.text.lower()\n",
    "                obj = None\n",
    "                for child in token.head.children:\n",
    "                    if child.dep_ in (\"dobj\", \"attr\") and child.pos_ in (\"NOUN\", \"PRON\"):\n",
    "                        obj = child.text.lower()\n",
    "                        triplets.append((subject, predicate, obj))\n",
    "                    elif child.dep_ == \"prep\":\n",
    "                        pobj = next((t for t in child.children if t.dep_ == \"pobj\"), None)\n",
    "                        if pobj:\n",
    "                            if obj:\n",
    "                                triplets.append((obj, child.text.lower(), pobj.text.lower()))\n",
    "                                for conj in pobj.children:\n",
    "                                    if conj.dep_ == \"conj\":\n",
    "                                        triplets.append((obj, child.text.lower(), conj.text.lower()))\n",
    "                            else:\n",
    "                                triplets.append((subject, predicate, pobj.text.lower()))\n",
    "\n",
    "        # 2. noun - prep - noun\n",
    "        for token in sent:\n",
    "            if token.dep_ == \"prep\" and token.head.pos_ == \"NOUN\":\n",
    "                pobj = next((child for child in token.children if child.dep_ == \"pobj\"), None)\n",
    "                if pobj:\n",
    "                    triplets.append((token.head.text.lower(), token.text.lower(), pobj.text.lower()))\n",
    "                    for conj in pobj.children:\n",
    "                        if conj.dep_ == \"conj\":\n",
    "                            triplets.append((token.head.text.lower(), token.text.lower(), conj.text.lower()))\n",
    "\n",
    "        # 3. noun - and - noun\n",
    "        for token in sent:\n",
    "            if token.dep_ == \"conj\" and token.head.pos_ == \"NOUN\":\n",
    "                for parent in token.head.children:\n",
    "                    if parent.dep_ in (\"det\", \"amod\"):\n",
    "                        triplets.append((token.head.text.lower(), \"and\", token.text.lower()))\n",
    "\n",
    "        # 4. amod verb + npadvmod\n",
    "        for token in sent:\n",
    "            if token.dep_ == \"amod\" and token.head.pos_ == \"NOUN\" and token.pos_ == \"VERB\":\n",
    "                modifier = next((child for child in token.children if child.dep_ == \"npadvmod\"), None)\n",
    "                if modifier:\n",
    "                    triplets.append((token.head.text.lower(), token.text.lower(), modifier.text.lower()))\n",
    "\n",
    "        # 5. tÃ­nh tá»« bá»• nghÄ©a cho danh tá»«\n",
    "        for token in sent:\n",
    "            if token.dep_ == \"amod\" and token.head.pos_ == \"NOUN\":\n",
    "                triplets.append((token.head.text.lower(), \"amod\", token.text.lower()))\n",
    "                # há»— trá»£ nhiá»u amod nhÆ°: black and white photo\n",
    "                for sibling in token.children:\n",
    "                    if sibling.dep_ == \"conj\" and sibling.pos_ == \"ADJ\":\n",
    "                        triplets.append((token.head.text.lower(), \"amod\", sibling.text.lower()))\n",
    "\n",
    "        # 6. advcl (while others wait)\n",
    "        for token in sent:\n",
    "            if token.dep_ == \"advcl\" and token.pos_ == \"VERB\":\n",
    "                verb = token.text.lower()\n",
    "                subject = None\n",
    "                obj = None\n",
    "                for child in token.children:\n",
    "                    if child.dep_ == \"nsubj\":\n",
    "                        subject = child.text.lower()\n",
    "                    elif child.dep_ in (\"dobj\", \"attr\", \"pobj\") and child.pos_ == \"NOUN\":\n",
    "                        obj = child.text.lower()\n",
    "                if subject:\n",
    "                    triplets.append((subject, verb, obj))\n",
    "\n",
    "        # 7. acl + to + amod/xcomp (e.g., kneeling to pet animals)\n",
    "        for token in sent:\n",
    "            if token.pos_ == \"VERB\" and token.dep_ == \"acl\":\n",
    "                subj = token.head.text.lower()\n",
    "                verb1 = token.text.lower()\n",
    "                triplets.append((subj, verb1, None))\n",
    "\n",
    "                for child in token.children:\n",
    "                    if child.dep_ == \"prep\" and child.text.lower() == \"to\":\n",
    "                        for grandchild in child.children:\n",
    "                            if grandchild.dep_ in (\"amod\", \"xcomp\") and grandchild.head.pos_ == \"NOUN\":\n",
    "                                triplets.append((subj, grandchild.text.lower(), grandchild.head.text.lower()))\n",
    "\n",
    "        # 8. conj Ä‘á»™ng tá»« (e.g., standing and sitting)\n",
    "        for token in sent:\n",
    "            if token.dep_ == \"conj\" and token.head.pos_ == \"VERB\":\n",
    "                subject = None\n",
    "                for sibling in token.head.children:\n",
    "                    if sibling.dep_ == \"nsubj\":\n",
    "                        subject = sibling.text.lower()\n",
    "                if subject:\n",
    "                    triplets.append((subject, token.text.lower(), None))\n",
    "\n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d1f34c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“¸ Testing image_id = 2299\n",
      "\n",
      "ðŸ“Œ Caption 1: Many small children are posing together in the black and white photo. \n",
      "   â†’ Triplet: ('children', 'posing', 'photo')\n",
      "   â†’ Triplet: ('children', 'amod', 'many')\n",
      "   â†’ Triplet: ('children', 'amod', 'small')\n",
      "   â†’ Triplet: ('photo', 'amod', 'black')\n",
      "   â†’ Triplet: ('photo', 'amod', 'white')\n",
      "\n",
      "ðŸ“Œ Caption 2: A vintage school picture of grade school aged children.\n",
      "   â†’ Triplet: ('picture', 'of', 'children')\n",
      "   â†’ Triplet: ('school', 'amod', 'vintage')\n",
      "   â†’ Triplet: ('children', 'amod', 'aged')\n",
      "\n",
      "ðŸ“Œ Caption 3: A black and white photo of a group of kids.\n",
      "   â†’ Triplet: ('photo', 'of', 'group')\n",
      "   â†’ Triplet: ('group', 'of', 'kids')\n",
      "   â†’ Triplet: ('photo', 'amod', 'black')\n",
      "   â†’ Triplet: ('photo', 'amod', 'white')\n",
      "\n",
      "ðŸ“Œ Caption 4: A group of children standing next to each other.\n",
      "   â†’ Triplet: ('group', 'of', 'children')\n",
      "   â†’ Triplet: ('group', 'standing', None)\n",
      "\n",
      "ðŸ“Œ Caption 5: A group of children standing and sitting beside each other. \n",
      "   â†’ Triplet: ('group', 'of', 'children')\n",
      "   â†’ Triplet: ('group', 'standing', None)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# ÄÆ°á»ng dáº«n tá»›i file caption COCO (báº¡n chá»‰nh náº¿u cáº§n)\n",
    "caption_file = \"E:/Download/annotations/captions_val2017.json\"\n",
    "\n",
    "# Load caption tá»« file JSON\n",
    "with open(caption_file, \"r\") as f:\n",
    "    caption_data = json.load(f)[\"annotations\"]\n",
    "\n",
    "# ID cáº§n kiá»ƒm thá»­\n",
    "test_image_id = 2299\n",
    "\n",
    "# Láº¥y 5 caption cá»§a áº£nh nÃ y\n",
    "captions = [item[\"caption\"] for item in caption_data if item[\"image_id\"] == test_image_id]\n",
    "\n",
    "# Kiá»ƒm thá»­ báº±ng extract_triplets()\n",
    "print(f\"\\nðŸ“¸ Testing image_id = {test_image_id}\")\n",
    "for i, caption in enumerate(captions, 1):\n",
    "    print(f\"\\nðŸ“Œ Caption {i}: {caption}\")\n",
    "    triplets = extract_triplets(caption)\n",
    "    if not triplets:\n",
    "        print(\"   â†’ âŒ KhÃ´ng trÃ­ch Ä‘Æ°á»£c triplet nÃ o.\")\n",
    "    else:\n",
    "        for trip in triplets:\n",
    "            print(\"   â†’ Triplet:\", trip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "45338e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_triplets(caption):\n",
    "    doc = nlp(caption)\n",
    "    triplets = []\n",
    "\n",
    "    for sent in doc.sents:\n",
    "        # 1. subject - verb - object\n",
    "        for token in sent:\n",
    "            if token.dep_ == \"nsubj\" and token.head.pos_ == \"VERB\":\n",
    "                subject = token.text.lower()\n",
    "                predicate = token.head.text.lower()\n",
    "                for child in token.head.children:\n",
    "                    if child.dep_ in (\"dobj\", \"attr\") and child.pos_ in (\"NOUN\", \"PRON\"):\n",
    "                        obj = child.text.lower()\n",
    "                        triplets.append((subject, predicate, obj))\n",
    "                    elif child.dep_ == \"prep\":\n",
    "                        pobj = next((t for t in child.children if t.dep_ == \"pobj\"), None)\n",
    "                        if pobj:\n",
    "                            triplets.append((subject, predicate, pobj.text.lower()))\n",
    "                if not any(t[0] == subject and t[1] == predicate for t in triplets):\n",
    "                    triplets.append((subject, predicate, None))\n",
    "\n",
    "        # 2. noun - prep - noun\n",
    "        for token in sent:\n",
    "            if token.dep_ == \"prep\" and token.head.pos_ == \"NOUN\":\n",
    "                pobj = next((child for child in token.children if child.dep_ == \"pobj\"), None)\n",
    "                if pobj:\n",
    "                    triplets.append((token.head.text.lower(), token.text.lower(), pobj.text.lower()))\n",
    "\n",
    "        # 3. conj nouns (e.g., \"head and neck\")\n",
    "        for token in sent:\n",
    "            if token.dep_ == \"conj\" and token.head.pos_ == \"NOUN\":\n",
    "                for parent in token.head.children:\n",
    "                    if parent.dep_ == \"prep\":\n",
    "                        pobj = next((child for child in parent.children if child.dep_ == \"pobj\"), None)\n",
    "                        if pobj:\n",
    "                            triplets.append((token.text.lower(), parent.text.lower(), pobj.text.lower()))\n",
    "                    elif parent.dep_ in (\"det\", \"amod\", \"compound\"):\n",
    "                        triplets.append((token.head.text.lower(), \"and\", token.text.lower()))\n",
    "\n",
    "        # 4. amod (e.g., \"white cake\")\n",
    "        for token in sent:\n",
    "            if token.dep_ == \"amod\" and token.head.pos_ == \"NOUN\":\n",
    "                triplets.append((token.head.text.lower(), \"amod\", token.text.lower()))\n",
    "\n",
    "        # 5. compound (e.g., \"close-up photo\")\n",
    "        for token in sent:\n",
    "            if token.dep_ == \"compound\" and token.head.pos_ == \"NOUN\":\n",
    "                compound_word = f\"{token.text.lower()}-{token.head.text.lower()}\"\n",
    "                triplets.append((compound_word, \"compound\", token.head.text.lower()))\n",
    "\n",
    "        # 6. acl (e.g., \"cake topped with berries\")\n",
    "        for token in sent:\n",
    "            if token.dep_ == \"acl\" and token.head.pos_ == \"NOUN\":\n",
    "                subj = token.head.text.lower()\n",
    "                verb = token.text.lower()\n",
    "                triplets.append((subj, verb, None))\n",
    "                for child in token.children:\n",
    "                    if child.dep_ == \"prep\":\n",
    "                        pobj = next((t for t in child.children if t.dep_ == \"pobj\"), None)\n",
    "                        if pobj:\n",
    "                            triplets.append((subj, verb, pobj.text.lower()))\n",
    "\n",
    "        # 7. verb with \"to\" + amod (e.g., \"kneeling to pet animals\")\n",
    "        for token in sent:\n",
    "            if token.pos_ == \"VERB\" and token.dep_ == \"acl\":\n",
    "                subj = token.head.text.lower()\n",
    "                verb1 = token.text.lower()\n",
    "                triplets.append((subj, verb1, None))\n",
    "                for child in token.children:\n",
    "                    if child.dep_ == \"prep\" and child.text.lower() == \"to\":\n",
    "                        for grandchild in child.children:\n",
    "                            if grandchild.dep_ in (\"amod\", \"xcomp\") and grandchild.head.pos_ == \"NOUN\":\n",
    "                                triplets.append((subj, grandchild.text.lower(), grandchild.head.text.lower()))\n",
    "\n",
    "        # 8. advcl (e.g., \"others wait\" in \"while others wait\")\n",
    "        for token in sent:\n",
    "            if token.dep_ == \"advcl\" and token.pos_ == \"VERB\":\n",
    "                subject = next((t for t in token.children if t.dep_ == \"nsubj\"), None)\n",
    "                if subject:\n",
    "                    triplets.append((subject.text.lower(), token.text.lower(), None))\n",
    "\n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a5241b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“¸ Testing image_id = 2157\n",
      "\n",
      "ðŸ“Œ Caption 1: A plate of finger foods next to a blue and raspberry topped cake.\n",
      "   â†’ Triplet: ('plate', 'of', 'foods')\n",
      "   â†’ Triplet: ('cake', 'amod', 'blue')\n",
      "   â†’ Triplet: ('cake', 'amod', 'topped')\n",
      "   â†’ Triplet: ('finger-foods', 'compound', 'foods')\n",
      "\n",
      "ðŸ“Œ Caption 2: A nicely set dining table filled with food and a cake topped with berries.\n",
      "   â†’ Triplet: ('table', 'amod', 'set')\n",
      "   â†’ Triplet: ('dining-table', 'compound', 'table')\n",
      "   â†’ Triplet: ('table', 'filled', None)\n",
      "   â†’ Triplet: ('table', 'filled', 'food')\n",
      "   â†’ Triplet: ('cake', 'topped', None)\n",
      "   â†’ Triplet: ('cake', 'topped', 'berries')\n",
      "   â†’ Triplet: ('table', 'filled', None)\n",
      "   â†’ Triplet: ('cake', 'topped', None)\n",
      "\n",
      "ðŸ“Œ Caption 3: a close up of a table with many plates of food\n",
      "   â†’ Triplet: ('close', 'with', 'plates')\n",
      "   â†’ Triplet: ('plates', 'of', 'food')\n",
      "   â†’ Triplet: ('plates', 'amod', 'many')\n",
      "\n",
      "ðŸ“Œ Caption 4: A table topped with a cake covered in berries next to a plate of sandwiches.\n",
      "   â†’ Triplet: ('plate', 'of', 'sandwiches')\n",
      "   â†’ Triplet: ('table', 'topped', None)\n",
      "   â†’ Triplet: ('table', 'topped', 'cake')\n",
      "   â†’ Triplet: ('cake', 'covered', None)\n",
      "   â†’ Triplet: ('cake', 'covered', 'berries')\n",
      "   â†’ Triplet: ('table', 'topped', None)\n",
      "   â†’ Triplet: ('cake', 'covered', None)\n",
      "\n",
      "ðŸ“Œ Caption 5: A white cake topped with berries and a plate of fruit and cheeses.\n",
      "   â†’ Triplet: ('plate', 'of', 'fruit')\n",
      "   â†’ Triplet: ('cake', 'amod', 'white')\n",
      "   â†’ Triplet: ('cake', 'topped', None)\n",
      "   â†’ Triplet: ('cake', 'topped', 'berries')\n",
      "   â†’ Triplet: ('cake', 'topped', None)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# ÄÆ°á»ng dáº«n tá»›i file caption COCO (báº¡n chá»‰nh náº¿u cáº§n)\n",
    "caption_file = \"E:/Download/annotations/captions_val2017.json\"\n",
    "\n",
    "# Load caption tá»« file JSON\n",
    "with open(caption_file, \"r\") as f:\n",
    "    caption_data = json.load(f)[\"annotations\"]\n",
    "\n",
    "# ID cáº§n kiá»ƒm thá»­\n",
    "test_image_id = 2157\n",
    "\n",
    "# Láº¥y 5 caption cá»§a áº£nh nÃ y\n",
    "captions = [item[\"caption\"] for item in caption_data if item[\"image_id\"] == test_image_id]\n",
    "\n",
    "# Kiá»ƒm thá»­ báº±ng extract_triplets()\n",
    "print(f\"\\nðŸ“¸ Testing image_id = {test_image_id}\")\n",
    "for i, caption in enumerate(captions, 1):\n",
    "    print(f\"\\nðŸ“Œ Caption {i}: {caption}\")\n",
    "    triplets = extract_triplets(caption)\n",
    "    if not triplets:\n",
    "        print(\"   â†’ âŒ KhÃ´ng trÃ­ch Ä‘Æ°á»£c triplet nÃ o.\")\n",
    "    else:\n",
    "        for trip in triplets:\n",
    "            print(\"   â†’ Triplet:\", trip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3ab92461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_triplets(caption):\n",
    "    doc = nlp(caption)\n",
    "    triplets = []\n",
    "\n",
    "    for sent in doc.sents:\n",
    "        # 1. subject - verb - object\n",
    "        for token in sent:\n",
    "            if token.dep_ == \"nsubj\" and token.head.pos_ == \"VERB\":\n",
    "                subject = token.text.lower()\n",
    "                predicate = token.head.text.lower()\n",
    "                object_ = None\n",
    "                for child in token.head.children:\n",
    "                    if child.dep_ in (\"dobj\", \"attr\") and child.pos_ in (\"NOUN\", \"PRON\", \"PROPN\"):\n",
    "                        object_ = child.text.lower()\n",
    "                        triplets.append((subject, predicate, object_))\n",
    "                    elif child.dep_ == \"prep\":\n",
    "                        pobj = next((t for t in child.children if t.dep_ == \"pobj\"), None)\n",
    "                        if pobj:\n",
    "                            object_ = pobj.text.lower()\n",
    "                            triplets.append((subject, predicate, object_))\n",
    "                if object_ is None:\n",
    "                    triplets.append((subject, predicate, None))\n",
    "\n",
    "        # 2. noun â€“ prep â€“ pobj\n",
    "        for token in sent:\n",
    "            if token.dep_ == \"prep\" and token.head.pos_ == \"NOUN\":\n",
    "                pobj = next((child for child in token.children if child.dep_ == \"pobj\"), None)\n",
    "                if pobj:\n",
    "                    triplets.append((token.head.text.lower(), token.text.lower(), pobj.text.lower()))\n",
    "\n",
    "        # 3. amod modifiers (multiple)\n",
    "        for token in sent:\n",
    "            if token.dep_ == \"amod\" and token.head.pos_ == \"NOUN\":\n",
    "                triplets.append((token.head.text.lower(), \"amod\", token.text.lower()))\n",
    "\n",
    "        # 4. compound (e.g. \"finger foods\", \"dining table\")\n",
    "        for token in sent:\n",
    "            if token.dep_ == \"compound\" and token.head.pos_ == \"NOUN\":\n",
    "                triplets.append((token.text.lower() + \"-\" + token.head.text.lower(), \"compound\", token.head.text.lower()))\n",
    "\n",
    "        # 5. conj (e.g., \"red and yellow apple and bananas\")\n",
    "        for token in sent:\n",
    "            if token.dep_ == \"conj\" and token.head.pos_ == \"NOUN\":\n",
    "                triplets.append((token.head.text.lower(), \"and\", token.text.lower()))\n",
    "                for child in token.children:\n",
    "                    if child.dep_ == \"amod\":\n",
    "                        triplets.append((token.text.lower(), \"amod\", child.text.lower()))\n",
    "\n",
    "        # 6. acl/advcl: noun with verb modifier\n",
    "        for token in sent:\n",
    "            if token.dep_ in (\"acl\", \"advcl\") and token.pos_ == \"VERB\" and token.head.pos_ == \"NOUN\":\n",
    "                subj = token.head.text.lower()\n",
    "                pred = token.text.lower()\n",
    "                obj = None\n",
    "                for child in token.children:\n",
    "                    if child.dep_ in (\"dobj\", \"pobj\", \"attr\") and child.pos_ in (\"NOUN\", \"PROPN\", \"PRON\"):\n",
    "                        obj = child.text.lower()\n",
    "                        triplets.append((subj, pred, obj))\n",
    "                triplets.append((subj, pred, obj))\n",
    "\n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "61c2216d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“¸ Testing image_id = 6012\n",
      "\n",
      "ðŸ“Œ Caption 1: There are bananas around another piece of fruit. \n",
      "   â†’ Triplet: ('bananas', 'around', 'piece')\n",
      "   â†’ Triplet: ('piece', 'of', 'fruit')\n",
      "\n",
      "ðŸ“Œ Caption 2: a yellow and red apple and some bananas\n",
      "   â†’ Triplet: ('apple', 'amod', 'yellow')\n",
      "   â†’ Triplet: ('apple', 'and', 'bananas')\n",
      "\n",
      "ðŸ“Œ Caption 3: An apple sits in between a bunch of bananas\n",
      "   â†’ Triplet: ('apple', 'sits', 'bunch')\n",
      "   â†’ Triplet: ('bunch', 'of', 'bananas')\n",
      "\n",
      "ðŸ“Œ Caption 4: A bunch of bananas with an apple sitting in the middle.\n",
      "   â†’ Triplet: ('bunch', 'of', 'bananas')\n",
      "   â†’ Triplet: ('bunch', 'with', 'apple')\n",
      "   â†’ Triplet: ('apple', 'sitting', None)\n",
      "\n",
      "ðŸ“Œ Caption 5: Six bananas and a red fruit make an artistic sight paired with a blue background.\n",
      "   â†’ Triplet: ('bananas', 'make', 'sight')\n",
      "   â†’ Triplet: ('fruit', 'amod', 'red')\n",
      "   â†’ Triplet: ('sight', 'amod', 'artistic')\n",
      "   â†’ Triplet: ('background', 'amod', 'blue')\n",
      "   â†’ Triplet: ('bananas', 'and', 'fruit')\n",
      "   â†’ Triplet: ('fruit', 'amod', 'red')\n",
      "   â†’ Triplet: ('sight', 'paired', None)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# ÄÆ°á»ng dáº«n tá»›i file caption COCO (báº¡n chá»‰nh náº¿u cáº§n)\n",
    "caption_file = \"E:/Download/annotations/captions_val2017.json\"\n",
    "\n",
    "# Load caption tá»« file JSON\n",
    "with open(caption_file, \"r\") as f:\n",
    "    caption_data = json.load(f)[\"annotations\"]\n",
    "\n",
    "# ID cáº§n kiá»ƒm thá»­\n",
    "test_image_id = 6012\n",
    "\n",
    "# Láº¥y 5 caption cá»§a áº£nh nÃ y\n",
    "captions = [item[\"caption\"] for item in caption_data if item[\"image_id\"] == test_image_id]\n",
    "\n",
    "# Kiá»ƒm thá»­ báº±ng extract_triplets()\n",
    "print(f\"\\nðŸ“¸ Testing image_id = {test_image_id}\")\n",
    "for i, caption in enumerate(captions, 1):\n",
    "    print(f\"\\nðŸ“Œ Caption {i}: {caption}\")\n",
    "    triplets = extract_triplets(caption)\n",
    "    if not triplets:\n",
    "        print(\"   â†’ âŒ KhÃ´ng trÃ­ch Ä‘Æ°á»£c triplet nÃ o.\")\n",
    "    else:\n",
    "        for trip in triplets:\n",
    "            print(\"   â†’ Triplet:\", trip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d6a12027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“¸ Testing image_id = 2157\n",
      "\n",
      "ðŸ“Œ Caption 1: A plate of finger foods next to a blue and raspberry topped cake.\n",
      "   â†’ Triplet: ('plate', 'of', 'foods')\n",
      "   â†’ Triplet: ('cake', 'amod', 'blue')\n",
      "   â†’ Triplet: ('cake', 'amod', 'topped')\n",
      "   â†’ Triplet: ('finger-foods', 'compound', 'foods')\n",
      "\n",
      "ðŸ“Œ Caption 2: A nicely set dining table filled with food and a cake topped with berries.\n",
      "   â†’ Triplet: ('table', 'amod', 'set')\n",
      "   â†’ Triplet: ('dining-table', 'compound', 'table')\n",
      "   â†’ Triplet: ('food', 'and', 'cake')\n",
      "   â†’ Triplet: ('table', 'filled', None)\n",
      "   â†’ Triplet: ('cake', 'topped', None)\n",
      "\n",
      "ðŸ“Œ Caption 3: a close up of a table with many plates of food\n",
      "   â†’ Triplet: ('close', 'with', 'plates')\n",
      "   â†’ Triplet: ('plates', 'of', 'food')\n",
      "   â†’ Triplet: ('plates', 'amod', 'many')\n",
      "\n",
      "ðŸ“Œ Caption 4: A table topped with a cake covered in berries next to a plate of sandwiches.\n",
      "   â†’ Triplet: ('plate', 'of', 'sandwiches')\n",
      "   â†’ Triplet: ('table', 'topped', None)\n",
      "   â†’ Triplet: ('cake', 'covered', None)\n",
      "\n",
      "ðŸ“Œ Caption 5: A white cake topped with berries and a plate of fruit and cheeses.\n",
      "   â†’ Triplet: ('plate', 'of', 'fruit')\n",
      "   â†’ Triplet: ('cake', 'amod', 'white')\n",
      "   â†’ Triplet: ('berries', 'and', 'plate')\n",
      "   â†’ Triplet: ('fruit', 'and', 'cheeses')\n",
      "   â†’ Triplet: ('cake', 'topped', None)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# ÄÆ°á»ng dáº«n tá»›i file caption COCO (báº¡n chá»‰nh náº¿u cáº§n)\n",
    "caption_file = \"E:/Download/annotations/captions_val2017.json\"\n",
    "\n",
    "# Load caption tá»« file JSON\n",
    "with open(caption_file, \"r\") as f:\n",
    "    caption_data = json.load(f)[\"annotations\"]\n",
    "\n",
    "# ID cáº§n kiá»ƒm thá»­\n",
    "test_image_id = 2157\n",
    "\n",
    "# Láº¥y 5 caption cá»§a áº£nh nÃ y\n",
    "captions = [item[\"caption\"] for item in caption_data if item[\"image_id\"] == test_image_id]\n",
    "\n",
    "# Kiá»ƒm thá»­ báº±ng extract_triplets()\n",
    "print(f\"\\nðŸ“¸ Testing image_id = {test_image_id}\")\n",
    "for i, caption in enumerate(captions, 1):\n",
    "    print(f\"\\nðŸ“Œ Caption {i}: {caption}\")\n",
    "    triplets = extract_triplets(caption)\n",
    "    if not triplets:\n",
    "        print(\"   â†’ âŒ KhÃ´ng trÃ­ch Ä‘Æ°á»£c triplet nÃ o.\")\n",
    "    else:\n",
    "        for trip in triplets:\n",
    "            print(\"   â†’ Triplet:\", trip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c42712e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_triplets(caption):\n",
    "    doc = nlp(caption)\n",
    "    triplets = []\n",
    "\n",
    "    for sent in doc.sents:\n",
    "        # 1. subject - verb - object\n",
    "        for token in sent:\n",
    "            if token.dep_ == \"nsubj\" and token.head.pos_ == \"VERB\":\n",
    "                subject = token.text.lower()\n",
    "                predicate = token.head.text.lower()\n",
    "                object_ = None\n",
    "                for child in token.head.children:\n",
    "                    if child.dep_ in (\"dobj\", \"attr\") and child.pos_ in (\"NOUN\", \"PRON\", \"PROPN\"):\n",
    "                        object_ = child.text.lower()\n",
    "                        triplets.append((subject, predicate, object_))\n",
    "                    elif child.dep_ == \"prep\":\n",
    "                        pobj = next((t for t in child.children if t.dep_ == \"pobj\"), None)\n",
    "                        if pobj:\n",
    "                            object_ = pobj.text.lower()\n",
    "                            triplets.append((subject, predicate, object_))\n",
    "                if object_ is None:\n",
    "                    triplets.append((subject, predicate, None))\n",
    "\n",
    "        # 2. noun â€“ prep â€“ pobj\n",
    "        for token in sent:\n",
    "            if token.dep_ == \"prep\" and token.head.pos_ == \"NOUN\":\n",
    "                pobj = next((child for child in token.children if child.dep_ == \"pobj\"), None)\n",
    "                if pobj:\n",
    "                    triplets.append((token.head.text.lower(), token.text.lower(), pobj.text.lower()))\n",
    "                    for conj in pobj.children:\n",
    "                        if conj.dep_ == \"conj\":\n",
    "                            triplets.append((token.head.text.lower(), token.text.lower(), conj.text.lower()))\n",
    "\n",
    "        # 3. amod modifiers (and chained)\n",
    "        for token in sent:\n",
    "            if token.dep_ == \"amod\" and token.head.pos_ == \"NOUN\":\n",
    "                triplets.append((token.head.text.lower(), \"amod\", token.text.lower()))\n",
    "                for sibling in token.children:\n",
    "                    if sibling.dep_ == \"conj\" and sibling.pos_ == \"ADJ\":\n",
    "                        triplets.append((token.head.text.lower(), \"amod\", sibling.text.lower()))\n",
    "\n",
    "        # 4. compound noun (e.g., dining-table)\n",
    "        for token in sent:\n",
    "            if token.dep_ == \"compound\" and token.head.pos_ == \"NOUN\":\n",
    "                compound_word = f\"{token.text.lower()}-{token.head.text.lower()}\"\n",
    "                triplets.append((compound_word, \"compound\", token.head.text.lower()))\n",
    "\n",
    "        # 5. conj nouns (apple and bananas)\n",
    "        for token in sent:\n",
    "            if token.dep_ == \"conj\" and token.head.pos_ == \"NOUN\":\n",
    "                triplets.append((token.head.text.lower(), \"and\", token.text.lower()))\n",
    "\n",
    "        # 6. acl / advcl\n",
    "        for token in sent:\n",
    "            if token.dep_ in (\"acl\", \"advcl\") and token.pos_ == \"VERB\" and token.head.pos_ == \"NOUN\":\n",
    "                subj = token.head.text.lower()\n",
    "                pred = token.text.lower()\n",
    "                obj = None\n",
    "                for child in token.children:\n",
    "                    if child.dep_ in (\"dobj\", \"pobj\", \"attr\") and child.pos_ in (\"NOUN\", \"PROPN\", \"PRON\"):\n",
    "                        obj = child.text.lower()\n",
    "                        triplets.append((subj, pred, obj))\n",
    "                    if child.dep_ == \"prep\":\n",
    "                        pobj = next((t for t in child.children if t.dep_ == \"pobj\"), None)\n",
    "                        if pobj:\n",
    "                            triplets.append((subj, pred, pobj.text.lower()))\n",
    "                triplets.append((subj, pred, obj))\n",
    "\n",
    "        # 7. acl + to + amod/xcomp (e.g., kneeling to pet animals)\n",
    "        for token in sent:\n",
    "            if token.pos_ == \"VERB\" and token.dep_ == \"acl\":\n",
    "                subj = token.head.text.lower()\n",
    "                verb1 = token.text.lower()\n",
    "                triplets.append((subj, verb1, None))\n",
    "                for child in token.children:\n",
    "                    if child.dep_ == \"prep\" and child.text.lower() == \"to\":\n",
    "                        for grandchild in child.children:\n",
    "                            if grandchild.dep_ in (\"amod\", \"xcomp\") and grandchild.head.pos_ == \"NOUN\":\n",
    "                                triplets.append((subj, grandchild.text.lower(), grandchild.head.text.lower()))\n",
    "\n",
    "        # 8. conj verb (e.g., standing and sitting)\n",
    "        for token in sent:\n",
    "            if token.dep_ == \"conj\" and token.head.pos_ == \"VERB\":\n",
    "                subject = None\n",
    "                for sibling in token.head.children:\n",
    "                    if sibling.dep_ == \"nsubj\":\n",
    "                        subject = sibling.text.lower()\n",
    "                if subject:\n",
    "                    triplets.append((subject, token.text.lower(), None))\n",
    "\n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eaaca470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“¸ Testing image_id = 2157\n",
      "\n",
      "ðŸ“Œ Caption 1: A plate of finger foods next to a blue and raspberry topped cake.\n",
      "   â†’ Triplet: ('plate', 'of', 'foods')\n",
      "   â†’ Triplet: ('cake', 'amod', 'blue')\n",
      "   â†’ Triplet: ('cake', 'amod', 'topped')\n",
      "   â†’ Triplet: ('finger-foods', 'compound', 'foods')\n",
      "\n",
      "ðŸ“Œ Caption 2: A nicely set dining table filled with food and a cake topped with berries.\n",
      "   â†’ Triplet: ('table', 'amod', 'set')\n",
      "   â†’ Triplet: ('dining-table', 'compound', 'table')\n",
      "   â†’ Triplet: ('food', 'and', 'cake')\n",
      "   â†’ Triplet: ('table', 'filled', 'food')\n",
      "   â†’ Triplet: ('table', 'filled', None)\n",
      "   â†’ Triplet: ('cake', 'topped', 'berries')\n",
      "   â†’ Triplet: ('cake', 'topped', None)\n",
      "   â†’ Triplet: ('table', 'filled', None)\n",
      "   â†’ Triplet: ('cake', 'topped', None)\n",
      "\n",
      "ðŸ“Œ Caption 3: a close up of a table with many plates of food\n",
      "   â†’ Triplet: ('close', 'with', 'plates')\n",
      "   â†’ Triplet: ('plates', 'of', 'food')\n",
      "   â†’ Triplet: ('plates', 'amod', 'many')\n",
      "\n",
      "ðŸ“Œ Caption 4: A table topped with a cake covered in berries next to a plate of sandwiches.\n",
      "   â†’ Triplet: ('plate', 'of', 'sandwiches')\n",
      "   â†’ Triplet: ('table', 'topped', 'cake')\n",
      "   â†’ Triplet: ('table', 'topped', None)\n",
      "   â†’ Triplet: ('cake', 'covered', 'berries')\n",
      "   â†’ Triplet: ('cake', 'covered', None)\n",
      "   â†’ Triplet: ('table', 'topped', None)\n",
      "   â†’ Triplet: ('cake', 'covered', None)\n",
      "\n",
      "ðŸ“Œ Caption 5: A white cake topped with berries and a plate of fruit and cheeses.\n",
      "   â†’ Triplet: ('plate', 'of', 'fruit')\n",
      "   â†’ Triplet: ('plate', 'of', 'cheeses')\n",
      "   â†’ Triplet: ('cake', 'amod', 'white')\n",
      "   â†’ Triplet: ('berries', 'and', 'plate')\n",
      "   â†’ Triplet: ('fruit', 'and', 'cheeses')\n",
      "   â†’ Triplet: ('cake', 'topped', 'berries')\n",
      "   â†’ Triplet: ('cake', 'topped', None)\n",
      "   â†’ Triplet: ('cake', 'topped', None)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# ÄÆ°á»ng dáº«n tá»›i file caption COCO (báº¡n chá»‰nh náº¿u cáº§n)\n",
    "caption_file = \"E:/Download/annotations/captions_val2017.json\"\n",
    "\n",
    "# Load caption tá»« file JSON\n",
    "with open(caption_file, \"r\") as f:\n",
    "    caption_data = json.load(f)[\"annotations\"]\n",
    "\n",
    "# ID cáº§n kiá»ƒm thá»­\n",
    "test_image_id = 2157\n",
    "\n",
    "# Láº¥y 5 caption cá»§a áº£nh nÃ y\n",
    "captions = [item[\"caption\"] for item in caption_data if item[\"image_id\"] == test_image_id]\n",
    "\n",
    "# Kiá»ƒm thá»­ báº±ng extract_triplets()\n",
    "print(f\"\\nðŸ“¸ Testing image_id = {test_image_id}\")\n",
    "for i, caption in enumerate(captions, 1):\n",
    "    print(f\"\\nðŸ“Œ Caption {i}: {caption}\")\n",
    "    triplets = extract_triplets(caption)\n",
    "    if not triplets:\n",
    "        print(\"   â†’ âŒ KhÃ´ng trÃ­ch Ä‘Æ°á»£c triplet nÃ o.\")\n",
    "    else:\n",
    "        for trip in triplets:\n",
    "            print(\"   â†’ Triplet:\", trip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "94a1ec5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“¸ Testing image_id = 6012\n",
      "\n",
      "ðŸ“Œ Caption 1: There are bananas around another piece of fruit. \n",
      "   â†’ Triplet: ('bananas', 'around', 'piece')\n",
      "   â†’ Triplet: ('piece', 'of', 'fruit')\n",
      "\n",
      "ðŸ“Œ Caption 2: a yellow and red apple and some bananas\n",
      "   â†’ Triplet: ('apple', 'amod', 'yellow')\n",
      "   â†’ Triplet: ('apple', 'amod', 'red')\n",
      "   â†’ Triplet: ('apple', 'and', 'bananas')\n",
      "\n",
      "ðŸ“Œ Caption 3: An apple sits in between a bunch of bananas\n",
      "   â†’ Triplet: ('apple', 'sits', 'bunch')\n",
      "   â†’ Triplet: ('bunch', 'of', 'bananas')\n",
      "\n",
      "ðŸ“Œ Caption 4: A bunch of bananas with an apple sitting in the middle.\n",
      "   â†’ Triplet: ('bunch', 'of', 'bananas')\n",
      "   â†’ Triplet: ('bunch', 'with', 'apple')\n",
      "   â†’ Triplet: ('apple', 'sitting', 'middle')\n",
      "   â†’ Triplet: ('apple', 'sitting', None)\n",
      "   â†’ Triplet: ('apple', 'sitting', None)\n",
      "\n",
      "ðŸ“Œ Caption 5: Six bananas and a red fruit make an artistic sight paired with a blue background.\n",
      "   â†’ Triplet: ('bananas', 'make', 'sight')\n",
      "   â†’ Triplet: ('fruit', 'amod', 'red')\n",
      "   â†’ Triplet: ('sight', 'amod', 'artistic')\n",
      "   â†’ Triplet: ('background', 'amod', 'blue')\n",
      "   â†’ Triplet: ('bananas', 'and', 'fruit')\n",
      "   â†’ Triplet: ('sight', 'paired', 'background')\n",
      "   â†’ Triplet: ('sight', 'paired', None)\n",
      "   â†’ Triplet: ('sight', 'paired', None)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# ÄÆ°á»ng dáº«n tá»›i file caption COCO (báº¡n chá»‰nh náº¿u cáº§n)\n",
    "caption_file = \"E:/Download/annotations/captions_val2017.json\"\n",
    "\n",
    "# Load caption tá»« file JSON\n",
    "with open(caption_file, \"r\") as f:\n",
    "    caption_data = json.load(f)[\"annotations\"]\n",
    "\n",
    "# ID cáº§n kiá»ƒm thá»­\n",
    "test_image_id = 6012\n",
    "\n",
    "# Láº¥y 5 caption cá»§a áº£nh nÃ y\n",
    "captions = [item[\"caption\"] for item in caption_data if item[\"image_id\"] == test_image_id]\n",
    "\n",
    "# Kiá»ƒm thá»­ báº±ng extract_triplets()\n",
    "print(f\"\\nðŸ“¸ Testing image_id = {test_image_id}\")\n",
    "for i, caption in enumerate(captions, 1):\n",
    "    print(f\"\\nðŸ“Œ Caption {i}: {caption}\")\n",
    "    triplets = extract_triplets(caption)\n",
    "    if not triplets:\n",
    "        print(\"   â†’ âŒ KhÃ´ng trÃ­ch Ä‘Æ°á»£c triplet nÃ o.\")\n",
    "    else:\n",
    "        for trip in triplets:\n",
    "            print(\"   â†’ Triplet:\", trip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0fe6a0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25014/25014 [03:05<00:00, 134.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÄÃ£ lÆ°u thÃ nh cÃ´ng.\n"
     ]
    }
   ],
   "source": [
    "# === Xá»­ lÃ½ file caption_val2017.json ===\n",
    "with open(\"E:/Download/annotations/captions_val2017.json\", \"r\") as f:\n",
    "    coco_data = json.load(f)\n",
    "\n",
    "results = []\n",
    "\n",
    "# Má»—i áº£nh sáº½ lÆ°u triplet khÃ´ng trÃ¹ng láº·p riÃªng\n",
    "image_triplet_set = {}\n",
    "\n",
    "for item in tqdm(coco_data[\"annotations\"]):\n",
    "    image_id = item[\"image_id\"]\n",
    "    caption = item[\"caption\"]\n",
    "    triplets = extract_triplets(caption)\n",
    "\n",
    "    if image_id not in image_triplet_set:\n",
    "        image_triplet_set[image_id] = set()\n",
    "\n",
    "    for triplet in triplets:\n",
    "        if triplet not in image_triplet_set[image_id]:\n",
    "            image_triplet_set[image_id].add(triplet)\n",
    "            subject, predicate, object_ = triplet\n",
    "            results.append({\n",
    "                \"subject\": subject,\n",
    "                \"predicate\": predicate,\n",
    "                \"object\": object_ if object_ else \"\",\n",
    "                \"image_id\": image_id\n",
    "            })\n",
    "\n",
    "# === LÆ°u file CSV Ä‘á»ƒ dÃ¹ng huáº¥n luyá»‡n ===\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"triplets_cleaned.csv\", index=False)\n",
    "print(\"ÄÃ£ lÆ°u thÃ nh cÃ´ng.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a9752f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sá»‘ lÆ°á»£ng triplet ban Ä‘áº§u: 81618\n",
      "Sá»‘ lÆ°á»£ng triplet sau khi loáº¡i bá» triplet thiáº¿u: 70810\n",
      "ÄÃ£ lÆ°u file triplets.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Äá»c file CSV\n",
    "df = pd.read_csv('triplets_cleaned.csv')\n",
    "\n",
    "# 2. Äáº¿m sá»‘ triplet ban Ä‘áº§u\n",
    "total_before = len(df)\n",
    "print(f\"Sá»‘ lÆ°á»£ng triplet ban Ä‘áº§u: {total_before}\")\n",
    "\n",
    "# 3. Loáº¡i bá» cÃ¡c triplet bá»‹ thiáº¿u subject, predicate hoáº·c object\n",
    "df_cleaned = df.dropna(subset=['subject', 'predicate', 'object'])\n",
    "df_cleaned = df_cleaned[(df_cleaned['subject'] != '') &\n",
    "                        (df_cleaned['predicate'] != '') &\n",
    "                        (df_cleaned['object'] != '')]\n",
    "\n",
    "# 4. Äáº¿m láº¡i sá»‘ lÆ°á»£ng triplet sau khi lÃ m sáº¡ch\n",
    "total_after = len(df_cleaned)\n",
    "print(f\"Sá»‘ lÆ°á»£ng triplet sau khi loáº¡i bá» triplet thiáº¿u: {total_after}\")\n",
    "\n",
    "# 5. Xuáº¥t ra file má»›i\n",
    "df_cleaned.to_csv('triplets.csv', index=False)\n",
    "print(\"ÄÃ£ lÆ°u file triplets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5489f74e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
